gumbel thresh: 0.505
mode: dy+bi+cl model path: ./ModelFile/crossView_NUCLA/Multi/dy+bi+cl/DIR-tenc-mean-nf-cl/ gpu: 4
is_clstoken  True
mean   True
seq_len  5
input projection present encoder:  4025
output projection present encoder:  4025
embed_dim:  8050
embed_proj_dim:  4025
ff_dim:  2048
num_heads:  7
num_layers:  2
dropout:  0.1
seq_len:  5
keys  odict_keys(['backbone.sparseCoding.rr', 'backbone.sparseCoding.theta', 'backbone.transformer_encoder.cls_token', 'backbone.transformer_encoder.input_layer.weight', 'backbone.transformer_encoder.input_layer.bias', 'backbone.transformer_encoder.output_layer.weight', 'backbone.transformer_encoder.output_layer.bias', 'backbone.transformer_encoder.pos_encoder.pe', 'backbone.transformer_encoder.encoder_layer.self_attn.in_proj_weight', 'backbone.transformer_encoder.encoder_layer.self_attn.in_proj_bias', 'backbone.transformer_encoder.encoder_layer.self_attn.out_proj.weight', 'backbone.transformer_encoder.encoder_layer.self_attn.out_proj.bias', 'backbone.transformer_encoder.encoder_layer.linear1.weight', 'backbone.transformer_encoder.encoder_layer.linear1.bias', 'backbone.transformer_encoder.encoder_layer.linear2.weight', 'backbone.transformer_encoder.encoder_layer.linear2.bias', 'backbone.transformer_encoder.encoder_layer.norm1.weight', 'backbone.transformer_encoder.encoder_layer.norm1.bias', 'backbone.transformer_encoder.encoder_layer.norm2.weight', 'backbone.transformer_encoder.encoder_layer.norm2.bias', 'backbone.transformer_encoder.transformer_encoder.layers.0.self_attn.in_proj_weight', 'backbone.transformer_encoder.transformer_encoder.layers.0.self_attn.in_proj_bias', 'backbone.transformer_encoder.transformer_encoder.layers.0.self_attn.out_proj.weight', 'backbone.transformer_encoder.transformer_encoder.layers.0.self_attn.out_proj.bias', 'backbone.transformer_encoder.transformer_encoder.layers.0.linear1.weight', 'backbone.transformer_encoder.transformer_encoder.layers.0.linear1.bias', 'backbone.transformer_encoder.transformer_encoder.layers.0.linear2.weight', 'backbone.transformer_encoder.transformer_encoder.layers.0.linear2.bias', 'backbone.transformer_encoder.transformer_encoder.layers.0.norm1.weight', 'backbone.transformer_encoder.transformer_encoder.layers.0.norm1.bias', 'backbone.transformer_encoder.transformer_encoder.layers.0.norm2.weight', 'backbone.transformer_encoder.transformer_encoder.layers.0.norm2.bias', 'backbone.transformer_encoder.transformer_encoder.layers.1.self_attn.in_proj_weight', 'backbone.transformer_encoder.transformer_encoder.layers.1.self_attn.in_proj_bias', 'backbone.transformer_encoder.transformer_encoder.layers.1.self_attn.out_proj.weight', 'backbone.transformer_encoder.transformer_encoder.layers.1.self_attn.out_proj.bias', 'backbone.transformer_encoder.transformer_encoder.layers.1.linear1.weight', 'backbone.transformer_encoder.transformer_encoder.layers.1.linear1.bias', 'backbone.transformer_encoder.transformer_encoder.layers.1.linear2.weight', 'backbone.transformer_encoder.transformer_encoder.layers.1.linear2.bias', 'backbone.transformer_encoder.transformer_encoder.layers.1.norm1.weight', 'backbone.transformer_encoder.transformer_encoder.layers.1.norm1.bias', 'backbone.transformer_encoder.transformer_encoder.layers.1.norm2.weight', 'backbone.transformer_encoder.transformer_encoder.layers.1.norm2.bias', 'backbone.Classifier.conv1.weight', 'backbone.Classifier.conv1.bias', 'backbone.Classifier.bn1.weight', 'backbone.Classifier.bn1.bias', 'backbone.Classifier.bn1.running_mean', 'backbone.Classifier.bn1.running_var', 'backbone.Classifier.bn1.num_batches_tracked', 'backbone.Classifier.conv2.weight', 'backbone.Classifier.conv2.bias', 'backbone.Classifier.bn2.weight', 'backbone.Classifier.bn2.bias', 'backbone.Classifier.bn2.running_mean', 'backbone.Classifier.bn2.running_var', 'backbone.Classifier.bn2.num_batches_tracked', 'backbone.Classifier.conv3.weight', 'backbone.Classifier.conv3.bias', 'backbone.Classifier.bn3.weight', 'backbone.Classifier.bn3.bias', 'backbone.Classifier.bn3.running_mean', 'backbone.Classifier.bn3.running_var', 'backbone.Classifier.bn3.num_batches_tracked', 'backbone.Classifier.conv4.weight', 'backbone.Classifier.conv4.bias', 'backbone.Classifier.bn4.weight', 'backbone.Classifier.bn4.bias', 'backbone.Classifier.bn4.running_mean', 'backbone.Classifier.bn4.running_var', 'backbone.Classifier.bn4.num_batches_tracked', 'backbone.Classifier.conv5.weight', 'backbone.Classifier.conv5.bias', 'backbone.Classifier.bn5.weight', 'backbone.Classifier.bn5.bias', 'backbone.Classifier.bn5.running_mean', 'backbone.Classifier.bn5.running_var', 'backbone.Classifier.bn5.num_batches_tracked', 'backbone.Classifier.conv6.weight', 'backbone.Classifier.conv6.bias', 'backbone.Classifier.bn6.weight', 'backbone.Classifier.bn6.bias', 'backbone.Classifier.bn6.running_mean', 'backbone.Classifier.bn6.running_var', 'backbone.Classifier.bn6.num_batches_tracked', 'backbone.Classifier.fc.weight', 'backbone.Classifier.fc.bias', 'backbone.Classifier.fc2.weight', 'backbone.Classifier.fc2.bias', 'backbone.Classifier.fc3.weight', 'backbone.Classifier.fc3.bias', 'backbone.Classifier.cls.0.weight', 'backbone.Classifier.cls.0.bias', 'proj.weight', 'proj.bias'])
cls token  tensor([[[ 0.0742, -0.6031, -0.0750,  ..., -1.3075,  0.4966, -0.7540]]],
       device='cuda:4')
rr  tensor([1.0738, 0.9827, 0.9756, 1.1247, 0.9363, 1.0295, 1.0171, 0.8772, 1.1414,
        0.8764, 1.0417, 1.0411, 0.9704, 0.8741, 1.0286, 0.8505, 1.1323, 1.0011,
        0.8609, 0.8905, 0.9876, 1.0116, 0.9802, 0.8808, 1.0316, 1.0559, 1.1463,
        1.0903, 0.9350, 1.0455, 0.9752, 0.8884, 0.8512, 1.0178, 1.0932, 1.1434,
        1.1080, 0.9231, 1.1499, 0.9333, 0.9124, 0.8827, 1.0343, 1.0172, 0.8646,
        1.1115, 0.8968, 1.1214, 1.1036, 1.0951, 0.9496, 1.1026, 1.0418, 0.9571,
        1.0756, 1.0673, 0.8579, 1.1263, 1.0073, 1.1280, 1.0781, 0.8988, 0.9347,
        1.0849, 1.0072, 0.9259, 1.0844, 0.8510, 0.8943, 0.8692, 1.0417, 1.1310,
        0.9874, 0.8866, 0.9528, 0.9757, 0.9415, 1.1430, 0.9416, 1.1242],
       device='cuda:4')
theta  tensor([1.3939, 2.4549, 1.6436, 1.5352, 0.7960, 3.0716, 2.6964, 2.0584, 0.7135,
        2.3078, 1.8680, 1.5814, 2.5930, 2.1385, 0.6050, 1.4292, 1.4744, 0.3818,
        2.0396, 2.8664, 0.4994, 2.8990, 1.4337, 2.9520, 2.1435, 1.2748, 0.3789,
        2.3218, 1.4669, 1.7877, 1.0691, 2.8505, 0.6513, 2.9708, 2.0885, 3.0277,
        1.2882, 1.7110, 2.6468, 2.2400, 1.1219, 0.2007, 0.5942, 0.7402, 2.4891,
        0.8861, 1.3891, 2.8232, 2.3094, 0.7382, 2.3175, 1.3819, 0.8533, 0.4777,
        3.0391, 1.8822, 1.2420, 3.1185, 0.1625, 0.9867, 1.3501, 2.3475, 1.5333,
        1.8721, 1.7133, 1.3431, 0.9326, 3.1381, 1.3014, 2.0869, 1.4987, 1.2876,
        2.5508, 0.4858, 1.6475, 0.5840, 1.7340, 1.2651, 3.0234, 2.8446],
       device='cuda:4')
cls  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:4')
pre_train: /home/balaji/crossView_CL/ModelFile/crossView_NUCLA/Multi/dy+bi+cl/dir-tenc-cl-mean/120.pth
loaded cls token  tensor([[[ 0.0678, -0.5492, -0.0683,  ..., -1.1908,  0.4520, -0.6864]]],
       device='cuda:4')
loaded rr  tensor([1.0599, 0.9743, 0.9663, 1.0703, 0.9268, 1.0206, 1.0072, 0.8694, 1.0412,
        0.8684, 1.0341, 1.0315, 0.9607, 0.8662, 0.9808, 0.8436, 1.0713, 0.9619,
        0.8533, 0.8830, 0.9458, 1.0024, 0.9725, 0.8735, 1.0197, 1.0501, 0.9950,
        1.0803, 0.9276, 1.0258, 0.9668, 0.8809, 0.8451, 1.0097, 1.0486, 1.0795,
        1.0817, 0.9156, 1.0775, 0.9241, 0.9034, 0.9111, 0.9747, 1.0095, 0.8571,
        1.0324, 0.8895, 1.0864, 1.0823, 1.0429, 0.9402, 1.0635, 0.9906, 0.9406,
        1.0659, 1.0572, 0.8507, 1.0796, 0.9868, 1.0320, 1.0559, 0.8908, 0.9269,
        1.0619, 0.9963, 0.9183, 1.0403, 0.8440, 0.8867, 0.8616, 1.0331, 1.0858,
        0.9757, 0.8722, 0.9442, 0.9596, 0.9335, 1.0722, 0.9340, 1.0885],
       device='cuda:4')
loaded theta  tensor([1.3831, 2.4351, 1.6302, 1.5173, 0.7894, 3.0460, 2.6738, 2.0410, 0.7377,
        2.2888, 1.8529, 1.5642, 2.5720, 2.1206, 0.6029, 1.4175, 1.4665, 0.3462,
        2.0224, 2.8426, 0.5185, 2.8750, 1.4217, 2.9278, 2.1216, 1.2670, 0.3556,
        2.2961, 1.4546, 1.7748, 1.0654, 2.8268, 0.6468, 2.9488, 2.0768, 3.0085,
        1.2792, 1.6970, 2.6287, 2.2216, 1.1125, 0.2004, 0.5884, 0.7404, 2.4684,
        0.9092, 1.3778, 2.8066, 2.2928, 0.7396, 2.2984, 1.3781, 0.8437, 0.4658,
        3.0172, 1.8672, 1.2320, 3.0912, 0.1108, 0.9424, 1.3398, 2.3283, 1.5204,
        1.8600, 1.6995, 1.3323, 0.9231, 3.1122, 1.2911, 2.0694, 1.4857, 1.2852,
        2.5297, 0.4884, 1.6341, 0.5822, 1.7197, 1.2677, 2.9984, 2.8182],
       device='cuda:4')
cls  tensor([0.8501, 0.8304, 0.8399, 0.8656, 0.7951, 0.8495, 0.8367, 0.8045, 0.8315,
        0.8346, 0.8355, 0.8365, 0.8201, 0.8282, 0.8473, 0.8448, 0.8442, 0.8319,
        0.8588, 0.8521, 0.8512, 0.8255, 0.8393, 0.8261, 0.8193, 0.8473, 0.8370,
        0.8597, 0.8751, 0.8255, 0.8253, 0.8407, 0.8280, 0.8370, 0.8604, 0.8473,
        0.8651, 0.8447, 0.8318, 0.8487, 0.8350, 0.8500, 0.8274, 0.8022, 0.8475,
        0.8413, 0.8316, 0.8393, 0.8229, 0.8409, 0.8307, 0.8596, 0.8457, 0.8425,
        0.8194, 0.8268, 0.8556, 0.8485, 0.8438, 0.8335, 0.8330, 0.8314, 0.8434,
        0.8416, 0.8375, 0.8239, 0.8493, 0.8421, 0.8607, 0.8365, 0.8267, 0.8485,
        0.8227, 0.8303, 0.8312, 0.8398, 0.8540, 0.8328, 0.8556, 0.8385, 0.8309,
        0.8417, 0.8307, 0.8517, 0.8200, 0.8409, 0.8578, 0.8444, 0.8580, 0.8369,
        0.8484, 0.8407, 0.8439, 0.8353, 0.8539, 0.8189, 0.8311, 0.8423, 0.8446,
        0.8441, 0.8261, 0.8253, 0.8221, 0.8547, 0.8060, 0.8552, 0.8289, 0.8427,
        0.8278, 0.8543, 0.8287, 0.8580, 0.8296, 0.8384, 0.8289, 0.8047, 0.8282,
        0.8393, 0.8169, 0.8399, 0.8317, 0.8332, 0.8359, 0.8187, 0.8432, 0.8413,
        0.8377, 0.8482, 0.8078, 0.8444, 0.8169, 0.8281, 0.8359, 0.8396, 0.8348,
        0.8171, 0.8313, 0.8224, 0.8377, 0.8497, 0.8353, 0.8440, 0.8315, 0.8469,
        0.8102, 0.8078, 0.8342, 0.8510, 0.8388, 0.8352, 0.8547, 0.8424, 0.8494,
        0.8638, 0.8326, 0.8254, 0.8351, 0.8287, 0.8268, 0.8180, 0.8465, 0.8523,
        0.8270, 0.8598, 0.8504, 0.8416, 0.8609, 0.8355, 0.8488, 0.8371, 0.8323,
        0.8245, 0.8379, 0.8567, 0.8400, 0.8372, 0.8174, 0.8401, 0.8387, 0.8265,
        0.8513, 0.8339, 0.8386, 0.8513, 0.8586, 0.8218, 0.8498, 0.8528, 0.8396,
        0.8472, 0.8293, 0.8510, 0.8413, 0.8074, 0.8183, 0.8274, 0.8327, 0.8312,
        0.8321, 0.8269, 0.8460, 0.8453, 0.8475, 0.8408, 0.8407, 0.8244, 0.8354,
        0.8692, 0.8126, 0.8381, 0.8449, 0.8511, 0.8666, 0.8418, 0.8452, 0.8232,
        0.8491, 0.8331, 0.8496, 0.8468, 0.8339, 0.8445, 0.8112, 0.8389, 0.8404,
        0.8571, 0.8222, 0.8481, 0.8239, 0.8462, 0.8429, 0.8447, 0.8126, 0.8151,
        0.8427, 0.8382, 0.8403, 0.8225, 0.8245, 0.8615, 0.8563, 0.8496, 0.8384,
        0.8114, 0.8336, 0.8185, 0.8292, 0.8423, 0.8759, 0.8117, 0.8445, 0.8326,
        0.8141, 0.8503, 0.8149, 0.8300], device='cuda:4')
plist  77
noplist  77
p  backbone.sparseCoding.rr False
p  backbone.sparseCoding.theta False
p  backbone.transformer_encoder.cls_token False
p  backbone.transformer_encoder.input_layer.weight False
p  backbone.transformer_encoder.input_layer.bias False
p  backbone.transformer_encoder.output_layer.weight False
p  backbone.transformer_encoder.output_layer.bias False
p  backbone.transformer_encoder.encoder_layer.self_attn.in_proj_weight False
p  backbone.transformer_encoder.encoder_layer.self_attn.in_proj_bias False
p  backbone.transformer_encoder.encoder_layer.self_attn.out_proj.weight False
p  backbone.transformer_encoder.encoder_layer.self_attn.out_proj.bias False
p  backbone.transformer_encoder.encoder_layer.linear1.weight False
p  backbone.transformer_encoder.encoder_layer.linear1.bias False
p  backbone.transformer_encoder.encoder_layer.linear2.weight False
p  backbone.transformer_encoder.encoder_layer.linear2.bias False
p  backbone.transformer_encoder.encoder_layer.norm1.weight False
p  backbone.transformer_encoder.encoder_layer.norm1.bias False
p  backbone.transformer_encoder.encoder_layer.norm2.weight False
p  backbone.transformer_encoder.encoder_layer.norm2.bias False
p  backbone.transformer_encoder.transformer_encoder.layers.0.self_attn.in_proj_weight False
p  backbone.transformer_encoder.transformer_encoder.layers.0.self_attn.in_proj_bias False
p  backbone.transformer_encoder.transformer_encoder.layers.0.self_attn.out_proj.weight False
p  backbone.transformer_encoder.transformer_encoder.layers.0.self_attn.out_proj.bias False
p  backbone.transformer_encoder.transformer_encoder.layers.0.linear1.weight False
p  backbone.transformer_encoder.transformer_encoder.layers.0.linear1.bias False
p  backbone.transformer_encoder.transformer_encoder.layers.0.linear2.weight False
p  backbone.transformer_encoder.transformer_encoder.layers.0.linear2.bias False
p  backbone.transformer_encoder.transformer_encoder.layers.0.norm1.weight False
p  backbone.transformer_encoder.transformer_encoder.layers.0.norm1.bias False
p  backbone.transformer_encoder.transformer_encoder.layers.0.norm2.weight False
p  backbone.transformer_encoder.transformer_encoder.layers.0.norm2.bias False
p  backbone.transformer_encoder.transformer_encoder.layers.1.self_attn.in_proj_weight False
p  backbone.transformer_encoder.transformer_encoder.layers.1.self_attn.in_proj_bias False
p  backbone.transformer_encoder.transformer_encoder.layers.1.self_attn.out_proj.weight False
p  backbone.transformer_encoder.transformer_encoder.layers.1.self_attn.out_proj.bias False
p  backbone.transformer_encoder.transformer_encoder.layers.1.linear1.weight False
p  backbone.transformer_encoder.transformer_encoder.layers.1.linear1.bias False
p  backbone.transformer_encoder.transformer_encoder.layers.1.linear2.weight False
p  backbone.transformer_encoder.transformer_encoder.layers.1.linear2.bias False
p  backbone.transformer_encoder.transformer_encoder.layers.1.norm1.weight False
p  backbone.transformer_encoder.transformer_encoder.layers.1.norm1.bias False
p  backbone.transformer_encoder.transformer_encoder.layers.1.norm2.weight False
p  backbone.transformer_encoder.transformer_encoder.layers.1.norm2.bias False
p  backbone.Classifier.conv1.weight True
p  backbone.Classifier.conv1.bias True
p  backbone.Classifier.bn1.weight True
p  backbone.Classifier.bn1.bias True
p  backbone.Classifier.conv2.weight True
p  backbone.Classifier.conv2.bias True
p  backbone.Classifier.bn2.weight True
p  backbone.Classifier.bn2.bias True
p  backbone.Classifier.conv3.weight True
p  backbone.Classifier.conv3.bias True
p  backbone.Classifier.bn3.weight True
p  backbone.Classifier.bn3.bias True
p  backbone.Classifier.conv4.weight True
p  backbone.Classifier.conv4.bias True
p  backbone.Classifier.bn4.weight True
p  backbone.Classifier.bn4.bias True
p  backbone.Classifier.conv5.weight True
p  backbone.Classifier.conv5.bias True
p  backbone.Classifier.bn5.weight True
p  backbone.Classifier.bn5.bias True
p  backbone.Classifier.conv6.weight True
p  backbone.Classifier.conv6.bias True
p  backbone.Classifier.bn6.weight True
p  backbone.Classifier.bn6.bias True
p  backbone.Classifier.fc.weight True
p  backbone.Classifier.fc.bias True
p  backbone.Classifier.fc2.weight True
p  backbone.Classifier.fc2.bias True
p  backbone.Classifier.fc3.weight True
p  backbone.Classifier.fc3.bias True
p  backbone.Classifier.cls.0.weight True
p  backbone.Classifier.cls.0.bias True
p  proj.weight False
p  proj.bias False
cls token  tensor([[[ 0.0678, -0.5492, -0.0683,  ..., -1.1908,  0.4520, -0.6864]]],
       device='cuda:4')
after rr  tensor([1.0599, 0.9743, 0.9663, 1.0703, 0.9268, 1.0206, 1.0072, 0.8694, 1.0412,
        0.8684, 1.0341, 1.0315, 0.9607, 0.8662, 0.9808, 0.8436, 1.0713, 0.9619,
        0.8533, 0.8830, 0.9458, 1.0024, 0.9725, 0.8735, 1.0197, 1.0501, 0.9950,
        1.0803, 0.9276, 1.0258, 0.9668, 0.8809, 0.8451, 1.0097, 1.0486, 1.0795,
        1.0817, 0.9156, 1.0775, 0.9241, 0.9034, 0.9111, 0.9747, 1.0095, 0.8571,
        1.0324, 0.8895, 1.0864, 1.0823, 1.0429, 0.9402, 1.0635, 0.9906, 0.9406,
        1.0659, 1.0572, 0.8507, 1.0796, 0.9868, 1.0320, 1.0559, 0.8908, 0.9269,
        1.0619, 0.9963, 0.9183, 1.0403, 0.8440, 0.8867, 0.8616, 1.0331, 1.0858,
        0.9757, 0.8722, 0.9442, 0.9596, 0.9335, 1.0722, 0.9340, 1.0885],
       device='cuda:4')
after theta  tensor([1.3831, 2.4351, 1.6302, 1.5173, 0.7894, 3.0460, 2.6738, 2.0410, 0.7377,
        2.2888, 1.8529, 1.5642, 2.5720, 2.1206, 0.6029, 1.4175, 1.4665, 0.3462,
        2.0224, 2.8426, 0.5185, 2.8750, 1.4217, 2.9278, 2.1216, 1.2670, 0.3556,
        2.2961, 1.4546, 1.7748, 1.0654, 2.8268, 0.6468, 2.9488, 2.0768, 3.0085,
        1.2792, 1.6970, 2.6287, 2.2216, 1.1125, 0.2004, 0.5884, 0.7404, 2.4684,
        0.9092, 1.3778, 2.8066, 2.2928, 0.7396, 2.2984, 1.3781, 0.8437, 0.4658,
        3.0172, 1.8672, 1.2320, 3.0912, 0.1108, 0.9424, 1.3398, 2.3283, 1.5204,
        1.8600, 1.6995, 1.3323, 0.9231, 3.1122, 1.2911, 2.0694, 1.4857, 1.2852,
        2.5297, 0.4884, 1.6341, 0.5822, 1.7197, 1.2677, 2.9984, 2.8182],
       device='cuda:4')
cls  tensor([0.8501, 0.8304, 0.8399, 0.8656, 0.7951, 0.8495, 0.8367, 0.8045, 0.8315,
        0.8346, 0.8355, 0.8365, 0.8201, 0.8282, 0.8473, 0.8448, 0.8442, 0.8319,
        0.8588, 0.8521, 0.8512, 0.8255, 0.8393, 0.8261, 0.8193, 0.8473, 0.8370,
        0.8597, 0.8751, 0.8255, 0.8253, 0.8407, 0.8280, 0.8370, 0.8604, 0.8473,
        0.8651, 0.8447, 0.8318, 0.8487, 0.8350, 0.8500, 0.8274, 0.8022, 0.8475,
        0.8413, 0.8316, 0.8393, 0.8229, 0.8409, 0.8307, 0.8596, 0.8457, 0.8425,
        0.8194, 0.8268, 0.8556, 0.8485, 0.8438, 0.8335, 0.8330, 0.8314, 0.8434,
        0.8416, 0.8375, 0.8239, 0.8493, 0.8421, 0.8607, 0.8365, 0.8267, 0.8485,
        0.8227, 0.8303, 0.8312, 0.8398, 0.8540, 0.8328, 0.8556, 0.8385, 0.8309,
        0.8417, 0.8307, 0.8517, 0.8200, 0.8409, 0.8578, 0.8444, 0.8580, 0.8369,
        0.8484, 0.8407, 0.8439, 0.8353, 0.8539, 0.8189, 0.8311, 0.8423, 0.8446,
        0.8441, 0.8261, 0.8253, 0.8221, 0.8547, 0.8060, 0.8552, 0.8289, 0.8427,
        0.8278, 0.8543, 0.8287, 0.8580, 0.8296, 0.8384, 0.8289, 0.8047, 0.8282,
        0.8393, 0.8169, 0.8399, 0.8317, 0.8332, 0.8359, 0.8187, 0.8432, 0.8413,
        0.8377, 0.8482, 0.8078, 0.8444, 0.8169, 0.8281, 0.8359, 0.8396, 0.8348,
        0.8171, 0.8313, 0.8224, 0.8377, 0.8497, 0.8353, 0.8440, 0.8315, 0.8469,
        0.8102, 0.8078, 0.8342, 0.8510, 0.8388, 0.8352, 0.8547, 0.8424, 0.8494,
        0.8638, 0.8326, 0.8254, 0.8351, 0.8287, 0.8268, 0.8180, 0.8465, 0.8523,
        0.8270, 0.8598, 0.8504, 0.8416, 0.8609, 0.8355, 0.8488, 0.8371, 0.8323,
        0.8245, 0.8379, 0.8567, 0.8400, 0.8372, 0.8174, 0.8401, 0.8387, 0.8265,
        0.8513, 0.8339, 0.8386, 0.8513, 0.8586, 0.8218, 0.8498, 0.8528, 0.8396,
        0.8472, 0.8293, 0.8510, 0.8413, 0.8074, 0.8183, 0.8274, 0.8327, 0.8312,
        0.8321, 0.8269, 0.8460, 0.8453, 0.8475, 0.8408, 0.8407, 0.8244, 0.8354,
        0.8692, 0.8126, 0.8381, 0.8449, 0.8511, 0.8666, 0.8418, 0.8452, 0.8232,
        0.8491, 0.8331, 0.8496, 0.8468, 0.8339, 0.8445, 0.8112, 0.8389, 0.8404,
        0.8571, 0.8222, 0.8481, 0.8239, 0.8462, 0.8429, 0.8447, 0.8126, 0.8151,
        0.8427, 0.8382, 0.8403, 0.8225, 0.8245, 0.8615, 0.8563, 0.8496, 0.8384,
        0.8114, 0.8336, 0.8185, 0.8292, 0.8423, 0.8759, 0.8117, 0.8445, 0.8326,
        0.8141, 0.8503, 0.8149, 0.8300], device='cuda:4')
optimizer  SGD (
Parameter Group 0
    dampening: 0
    lr: 0.0001
    momentum: 0.9
    nesterov: False
    weight_decay: 0.001
)
start training epoch: 0
epoch: 0 |loss: 4.12601281888783 |cls: 2.0580300628207624 |mse: 0.00841281969769625 |bi: 0.015398775747598847
training time(min): 8.665899125734965
sample: 0
sample: 1
sample: 2
sample: 3
sample: 4
sample: 5
sample: 6
sample: 7
sample: 8
sample: 9
sample: 10
sample: 11
sample: 12
sample: 13
sample: 14
sample: 15
sample: 16
sample: 17
sample: 18
sample: 19
sample: 20
sample: 21
sample: 22
sample: 23
sample: 24
sample: 25
sample: 26
sample: 27
sample: 28
sample: 29
sample: 30
sample: 31
sample: 32
sample: 33
sample: 34
sample: 35
sample: 36
sample: 37
sample: 38
sample: 39
sample: 40
sample: 41
sample: 42
sample: 43
sample: 44
sample: 45
sample: 46
sample: 47
sample: 48
sample: 49
sample: 50
sample: 51
sample: 52
sample: 53
sample: 54
sample: 55
sample: 56
sample: 57
testing epoch: 0 Acc:0.2198
start training epoch: 1
epoch: 1 |loss: 3.507027553394437 |cls: 1.7485404713079333 |mse: 0.008405254935496487 |bi: 0.01541352273125085
training time(min): 9.673554289340974
start training epoch: 2
epoch: 2 |loss: 3.3566605299711227 |cls: 1.673337958753109 |mse: 0.008442441730949213 |bi: 0.015421658223203849
training time(min): 10.117695542176564
start training epoch: 3
epoch: 3 |loss: 3.241960680577904 |cls: 1.6159995757043362 |mse: 0.008419482168392278 |bi: 0.015420543721120339
training time(min): 9.970007987817128
start training epoch: 4
epoch: 4 |loss: 3.1362915546633303 |cls: 1.5631592134013772 |mse: 0.008430798105109716 |bi: 0.015423341443238314
training time(min): 9.700217684110006
start training epoch: 5
epoch: 5 |loss: 3.076770889107138 |cls: 1.5334091542754322 |mse: 0.00841193831183773 |bi: 0.0154064487433061
training time(min): 9.713935939470927
start training epoch: 6
epoch: 6 |loss: 3.0142998197115958 |cls: 1.5021737639326602 |mse: 0.008410673684920766 |bi: 0.015416214318975108
training time(min): 10.035425905386607
start training epoch: 7
epoch: 7 |loss: 2.953128751832992 |cls: 1.4715760094113648 |mse: 0.008434230594502878 |bi: 0.015424979133968009
training time(min): 10.026242339611054
start training epoch: 8
epoch: 8 |loss: 2.901218880433589 |cls: 1.4456247857306153 |mse: 0.00842675822059391 |bi: 0.015425517445692094
training time(min): 9.732198258241018
start training epoch: 9
epoch: 9 |loss: 2.862213901244104 |cls: 1.426122404402122 |mse: 0.008428035258475575 |bi: 0.015410543026519008
training time(min): 9.676832588513692
start training epoch: 10
epoch: 10 |loss: 2.7997357472777367 |cls: 1.394873775774613 |mse: 0.008443757333225221 |bi: 0.015444442131411051
training time(min): 9.751652963956197
sample: 0
sample: 1
sample: 2
sample: 3
sample: 4
sample: 5
sample: 6
sample: 7
sample: 8
sample: 9
sample: 10
sample: 11
sample: 12
sample: 13
sample: 14
sample: 15
sample: 16
sample: 17
sample: 18
sample: 19
sample: 20
sample: 21
sample: 22
sample: 23
sample: 24
sample: 25
sample: 26
sample: 27
sample: 28
sample: 29
sample: 30
sample: 31
sample: 32
sample: 33
sample: 34
sample: 35
sample: 36
sample: 37
sample: 38
sample: 39
sample: 40
sample: 41
sample: 42
sample: 43
sample: 44
sample: 45
sample: 46
sample: 47
sample: 48
sample: 49
sample: 50
sample: 51
sample: 52
sample: 53
sample: 54
sample: 55
sample: 56
sample: 57
testing epoch: 10 Acc:0.2845
start training epoch: 11
epoch: 11 |loss: 2.8008466395549476 |cls: 1.3954430606681854 |mse: 0.00842047483092756 |bi: 0.01540045891306363
training time(min): 10.023763144016266
start training epoch: 12
epoch: 12 |loss: 2.737659845035523 |cls: 1.3638505714479834 |mse: 0.008416247328568716 |bi: 0.015424607641762123
training time(min): 10.11291780869166
start training epoch: 13
epoch: 13 |loss: 2.6281023353803903 |cls: 1.3090770714916289 |mse: 0.008407577812249656 |bi: 0.015406130263727391
training time(min): 10.144193351268768
start training epoch: 14
epoch: 14 |loss: 2.590741960797459 |cls: 1.2903945248108357 |mse: 0.008410559734329581 |bi: 0.015423500659380807
training time(min): 10.196790766716003
start training epoch: 15
epoch: 15 |loss: 2.566357735078782 |cls: 1.2781786161940545 |mse: 0.008458097247057594 |bi: 0.015424076893395977
training time(min): 9.692550384998322
start training epoch: 16
epoch: 16 |loss: 2.58075645705685 |cls: 1.2853876322042197 |mse: 0.008438759005002794 |bi: 0.015424418059410527
training time(min): 9.809928174813589
start training epoch: 17
epoch: 17 |loss: 2.470787768717855 |cls: 1.2304265960119665 |mse: 0.008394893059630704 |bi: 0.01539681952635874
training time(min): 10.282567568620046
start training epoch: 18
epoch: 18 |loss: 2.446509711910039 |cls: 1.2182745817117393 |mse: 0.008419934869380086 |bi: 0.01540612270400743
training time(min): 11.52036741177241
start training epoch: 19
epoch: 19 |loss: 2.3648674436844885 |cls: 1.1774496040306985 |mse: 0.008425048838034854 |bi: 0.015431954634550493
training time(min): 11.606586054960887
start training epoch: 20
epoch: 20 |loss: 2.3383064507506788 |cls: 1.1641742788488045 |mse: 0.008417767863647896 |bi: 0.01540117921831552
training time(min): 11.44988736708959
sample: 0
sample: 1
sample: 2
sample: 3
sample: 4
sample: 5
sample: 6
sample: 7
sample: 8
sample: 9
sample: 10
sample: 11
sample: 12
sample: 13
sample: 14
sample: 15
sample: 16
sample: 17
sample: 18
sample: 19
sample: 20
sample: 21
sample: 22
sample: 23
sample: 24
sample: 25
sample: 26
sample: 27
sample: 28
sample: 29
sample: 30
sample: 31
sample: 32
sample: 33
sample: 34
sample: 35
sample: 36
sample: 37
sample: 38
sample: 39
sample: 40
sample: 41
sample: 42
sample: 43
sample: 44
sample: 45
sample: 46
sample: 47
sample: 48
sample: 49
sample: 50
sample: 51
sample: 52
sample: 53
sample: 54
sample: 55
sample: 56
sample: 57
testing epoch: 20 Acc:0.3147
start training epoch: 21
epoch: 21 |loss: 2.3406877715606242 |cls: 1.1653446379350498 |mse: 0.008454192669887561 |bi: 0.015442994015756994
training time(min): 10.697247886657715
start training epoch: 22
epoch: 22 |loss: 2.2702982949558645 |cls: 1.1301777315093204 |mse: 0.008402093128097476 |bi: 0.015407434333610581
training time(min): 11.017698450883229
start training epoch: 23
epoch: 23 |loss: 2.2010543232318014 |cls: 1.0955540899885818 |mse: 0.008404247246289742 |bi: 0.015419042440043995
training time(min): 11.180902365843455
start training epoch: 24
epoch: 24 |loss: 2.1826845346949995 |cls: 1.086359460838139 |mse: 0.008423917724940111 |bi: 0.015416957401612308
training time(min): 11.7571390748024
start training epoch: 25
epoch: 25 |loss: 2.180338638368994 |cls: 1.0851777282659896 |mse: 0.008438906068477081 |bi: 0.01544278168148594
training time(min): 11.71274090607961
start training epoch: 26
epoch: 26 |loss: 2.1272836490534246 |cls: 1.0586604691343382 |mse: 0.008420239097176818 |bi: 0.015424691016960423
training time(min): 11.25740195910136
start training epoch: 27
epoch: 27 |loss: 2.0739890839904547 |cls: 1.0320157129317522 |mse: 0.00841638876045181 |bi: 0.015412673576065572
training time(min): 11.283394300937653
start training epoch: 28
epoch: 28 |loss: 2.026953287422657 |cls: 1.0085031789494678 |mse: 0.00840784048432397 |bi: 0.015390852513519349
training time(min): 11.290462795893351
start training epoch: 29
epoch: 29 |loss: 2.050205356441438 |cls: 1.0201208575163037 |mse: 0.008420656087764655 |bi: 0.015429907449288294
training time(min): 11.074387991428376
start training epoch: 30
epoch: 30 |loss: 1.9579845434054732 |cls: 0.9739944287575781 |mse: 0.008451803138086689 |bi: 0.015438846665347228
training time(min): 11.309540271759033
sample: 0
sample: 1
sample: 2
sample: 3
sample: 4
sample: 5
sample: 6
sample: 7
sample: 8
sample: 9
sample: 10
sample: 11
sample: 12
sample: 13
sample: 14
sample: 15
sample: 16
sample: 17
sample: 18
sample: 19
sample: 20
sample: 21
sample: 22
sample: 23
sample: 24
sample: 25
sample: 26
sample: 27
sample: 28
sample: 29
sample: 30
sample: 31
sample: 32
sample: 33
sample: 34
sample: 35
sample: 36
sample: 37
sample: 38
sample: 39
sample: 40
sample: 41
sample: 42
sample: 43
sample: 44
sample: 45
sample: 46
sample: 47
sample: 48
sample: 49
sample: 50
sample: 51
sample: 52
sample: 53
sample: 54
sample: 55
sample: 56
sample: 57
testing epoch: 30 Acc:0.3599
start training epoch: 31
epoch: 31 |loss: 1.923279485432431 |cls: 0.9566458219196647 |mse: 0.008443570612143958 |bi: 0.015442645199073013
training time(min): 11.561305002371471
start training epoch: 32
epoch: 32 |loss: 1.8841265479568392 |cls: 0.9370948765426874 |mse: 0.008396582845307421 |bi: 0.015402073884615675
training time(min): 11.67267592350642
start training epoch: 33
epoch: 33 |loss: 1.851622017333284 |cls: 0.9208229476353154 |mse: 0.008433497092482867 |bi: 0.015426245332491817
training time(min): 11.420485750834148
start training epoch: 34
epoch: 34 |loss: 1.839538902277127 |cls: 0.914781907456927 |mse: 0.008432555900071748 |bi: 0.01542526729463134
training time(min): 11.441851512591045
start training epoch: 35
epoch: 35 |loss: 1.8200684962794185 |cls: 0.9050467915367335 |mse: 0.008432823153270874 |bi: 0.015420922754856292
training time(min): 11.578137115637462
start training epoch: 36
epoch: 36 |loss: 1.7889778882963583 |cls: 0.8894935959251598 |mse: 0.008446412317425711 |bi: 0.015442857478774386
training time(min): 12.688831007480621
start training epoch: 37
epoch: 37 |loss: 1.756067487411201 |cls: 0.8730449786526151 |mse: 0.008433793134827283 |bi: 0.015437398411449976
training time(min): 13.268496612707773
start training epoch: 38
epoch: 38 |loss: 1.6662828521803021 |cls: 0.8281666199909523 |mse: 0.00840836339739326 |bi: 0.015412521926918998
training time(min): 13.554199576377869
start training epoch: 39
epoch: 39 |loss: 1.665811620769091 |cls: 0.82791884674225 |mse: 0.008430800846326747 |bi: 0.015431203988555353
training time(min): 13.20299853483836
start training epoch: 40
epoch: 40 |loss: 1.6921927522635087 |cls: 0.8411155968206003 |mse: 0.008420000855039689 |bi: 0.015415600155392895
training time(min): 13.388362212975819
sample: 0
sample: 1
sample: 2
sample: 3
sample: 4
sample: 5
sample: 6
sample: 7
sample: 8
sample: 9
sample: 10
sample: 11
sample: 12
sample: 13
sample: 14
sample: 15
sample: 16
sample: 17
sample: 18
sample: 19
sample: 20
sample: 21
sample: 22
sample: 23
sample: 24
sample: 25
sample: 26
sample: 27
sample: 28
sample: 29
sample: 30
sample: 31
sample: 32
sample: 33
sample: 34
sample: 35
sample: 36
sample: 37
sample: 38
sample: 39
sample: 40
sample: 41
sample: 42
sample: 43
sample: 44
sample: 45
sample: 46
sample: 47
sample: 48
sample: 49
sample: 50
sample: 51
sample: 52
sample: 53
sample: 54
sample: 55
sample: 56
sample: 57
testing epoch: 40 Acc:0.3599
start training epoch: 41
epoch: 41 |loss: 1.5792794860899448 |cls: 0.7846667756093666 |mse: 0.00840578672978154 |bi: 0.015401512806420214
training time(min): 12.801853477954865
start training epoch: 42
epoch: 42 |loss: 1.5789115400984883 |cls: 0.7844871601555496 |mse: 0.008397129173317808 |bi: 0.015400959360704292
training time(min): 12.898797806104024
start training epoch: 43
epoch: 43 |loss: 1.5169351145159453 |cls: 0.7534817447303794 |mse: 0.00842903553711949 |bi: 0.015425858662638348
training time(min): 14.023560571670533
start training epoch: 44
epoch: 44 |loss: 1.5431358881760389 |cls: 0.7665863651782274 |mse: 0.00842262332480459 |bi: 0.015405326601467095
training time(min): 13.212200506528218
start training epoch: 45
epoch: 45 |loss: 1.4873715908033773 |cls: 0.7386788572766818 |mse: 0.008467324749290128 |bi: 0.01546552015497582
training time(min): 13.436659638086955
start training epoch: 46
epoch: 46 |loss: 1.4924690879997797 |cls: 0.7412493379088119 |mse: 0.008429006460573873 |bi: 0.015414038334711222
training time(min): 13.30377432902654
start training epoch: 47
epoch: 47 |loss: 1.4762477712938562 |cls: 0.7331535269040614 |mse: 0.008399417905820883 |bi: 0.015412946548167383
training time(min): 13.823833072185517
start training epoch: 48
epoch: 48 |loss: 1.4250723228324205 |cls: 0.7075618982780725 |mse: 0.008406831466345466 |bi: 0.015416927042679163
training time(min): 13.48064462741216
start training epoch: 49
epoch: 49 |loss: 1.3735485774232075 |cls: 0.6817883147741668 |mse: 0.00842994263075525 |bi: 0.015420073556015268
training time(min): 13.298610866069794
start training epoch: 50
epoch: 50 |loss: 1.1845790856750682 |cls: 0.5873056701384485 |mse: 0.008424450279562734 |bi: 0.015432955417054472
training time(min): 13.412368110815684
sample: 0
sample: 1
sample: 2
sample: 3
sample: 4
sample: 5
sample: 6
sample: 7
sample: 8
sample: 9
sample: 10
sample: 11
sample: 12
sample: 13
sample: 14
sample: 15
sample: 16
sample: 17
sample: 18
sample: 19
sample: 20
sample: 21
sample: 22
sample: 23
sample: 24
sample: 25
sample: 26
sample: 27
sample: 28
sample: 29
sample: 30
sample: 31
sample: 32
sample: 33
sample: 34
sample: 35
sample: 36
sample: 37
sample: 38
sample: 39
sample: 40
sample: 41
sample: 42
sample: 43
sample: 44
sample: 45
sample: 46
sample: 47
sample: 48
sample: 49
sample: 50
sample: 51
sample: 52
sample: 53
sample: 54
sample: 55
sample: 56
sample: 57
testing epoch: 50 Acc:0.4418
start training epoch: 51
epoch: 51 |loss: 1.1615037966985255 |cls: 0.5757663653930649 |mse: 0.00842835936055053 |bi: 0.015427079357323237
training time(min): 13.913884790738424
start training epoch: 52
epoch: 52 |loss: 1.1076019189786166 |cls: 0.5488273569499142 |mse: 0.008406206925428705 |bi: 0.015409943993290653
training time(min): 12.846449732780457
start training epoch: 53
epoch: 53 |loss: 1.163972845650278 |cls: 0.5770074594474863 |mse: 0.008416017479248694 |bi: 0.015419049999763956
training time(min): 13.112786606947582
start training epoch: 54
epoch: 54 |loss: 1.1097709585446864 |cls: 0.5499113680562004 |mse: 0.008407838839048054 |bi: 0.015403885987325339
training time(min): 13.886017739772797
start training epoch: 55
epoch: 55 |loss: 1.049526755406987 |cls: 0.5197569699812448 |mse: 0.008468082365652663 |bi: 0.015447353645868134
training time(min): 13.254877416292826
start training epoch: 56
epoch: 56 |loss: 1.0986170457908884 |cls: 0.5443321836792165 |mse: 0.008412035032961285 |bi: 0.015406403250381118
training time(min): 13.364006392161052
start training epoch: 57
epoch: 57 |loss: 1.0236014192341827 |cls: 0.5068338811397552 |mse: 0.008393805945161148 |bi: 0.01539851035704487
training time(min): 14.051626241207122
start training epoch: 58
epoch: 58 |loss: 1.0400798488408327 |cls: 0.5150697362842038 |mse: 0.008400657230595243 |bi: 0.015397153179947054
training time(min): 13.577884578704834
start training epoch: 59
epoch: 59 |loss: 1.0362462337943725 |cls: 0.513133957865648 |mse: 0.008435497768005007 |bi: 0.015428224309289362
training time(min): 13.450733077526092
start training epoch: 60
epoch: 60 |loss: 1.0266911216895096 |cls: 0.5083610868023243 |mse: 0.00842796820870717 |bi: 0.015409777202876285
training time(min): 14.032606438795726
sample: 0
sample: 1
sample: 2
sample: 3
sample: 4
sample: 5
sample: 6
sample: 7
sample: 8
sample: 9
sample: 10
sample: 11
sample: 12
sample: 13
sample: 14
sample: 15
sample: 16
sample: 17
sample: 18
sample: 19
sample: 20
sample: 21
sample: 22
sample: 23
sample: 24
sample: 25
sample: 26
sample: 27
sample: 28
sample: 29
sample: 30
sample: 31
sample: 32
sample: 33
sample: 34
sample: 35
sample: 36
sample: 37
sample: 38
sample: 39
sample: 40
sample: 41
sample: 42
sample: 43
sample: 44
sample: 45
sample: 46
sample: 47
sample: 48
sample: 49
sample: 50
sample: 51
sample: 52
sample: 53
sample: 54
sample: 55
sample: 56
sample: 57
testing epoch: 60 Acc:0.4267
start training epoch: 61
epoch: 61 |loss: 1.0641267404716928 |cls: 0.5270952404098352 |mse: 0.008395644164920668 |bi: 0.015406130281917285
training time(min): 13.133514591058095
start training epoch: 62
epoch: 62 |loss: 1.0228079435764812 |cls: 0.5064253798336722 |mse: 0.008415258142122184 |bi: 0.015419239582115551
training time(min): 12.148513225714366
start training epoch: 63
epoch: 63 |loss: 0.9715398829430342 |cls: 0.48078669235110283 |mse: 0.008424616140473518 |bi: 0.015418784660141682
training time(min): 12.550449168682098
start training epoch: 64
epoch: 64 |loss: 0.9402777443174273 |cls: 0.46515621573780663 |mse: 0.008424369676504284 |bi: 0.01540945873784949
training time(min): 11.148298267523447
start training epoch: 65
epoch: 65 |loss: 0.9459013700252399 |cls: 0.4679713922960218 |mse: 0.008417817733061383 |bi: 0.015407692153530661
training time(min): 11.164741400877634
start training epoch: 66
epoch: 66 |loss: 0.9607973679667339 |cls: 0.4754071556671988 |mse: 0.008440939065621933 |bi: 0.015421180552948499
training time(min): 11.46796788374583
start training epoch: 67
epoch: 67 |loss: 0.9781889098230749 |cls: 0.48410107419476844 |mse: 0.008443330340014654 |bi: 0.01543432015387225
training time(min): 11.134036068121592
start training epoch: 68
epoch: 68 |loss: 0.9366175356553867 |cls: 0.463333851628704 |mse: 0.008408967887589824 |bi: 0.015408602001116378
training time(min): 10.744224341710408
start training epoch: 69
epoch: 69 |loss: 0.9559030723758042 |cls: 0.47296820109477267 |mse: 0.008424540490523214 |bi: 0.01542132464601309
training time(min): 11.150823672612509
start training epoch: 70
epoch: 70 |loss: 0.9669647163827904 |cls: 0.4784955183858983 |mse: 0.008431408830801956 |bi: 0.015422734912135638
training time(min): 11.199357283115386
sample: 0
sample: 1
sample: 2
sample: 3
sample: 4
sample: 5
sample: 6
sample: 7
sample: 8
sample: 9
sample: 10
sample: 11
sample: 12
sample: 13
sample: 14
sample: 15
sample: 16
sample: 17
sample: 18
sample: 19
sample: 20
sample: 21
sample: 22
sample: 23
sample: 24
sample: 25
sample: 26
sample: 27
sample: 28
sample: 29
sample: 30
sample: 31
sample: 32
sample: 33
sample: 34
sample: 35
sample: 36
sample: 37
sample: 38
sample: 39
sample: 40
sample: 41
sample: 42
sample: 43
sample: 44
sample: 45
sample: 46
sample: 47
sample: 48
sample: 49
sample: 50
sample: 51
sample: 52
sample: 53
sample: 54
sample: 55
sample: 56
sample: 57
testing epoch: 70 Acc:0.4461
start training epoch: 71
epoch: 71 |loss: 0.9239913570927456 |cls: 0.45700376862077974 |mse: 0.008440887620963622 |bi: 0.015429323586431565
training time(min): 11.361138959725698
start training epoch: 72
epoch: 72 |loss: 0.916287454077974 |cls: 0.4531767473963555 |mse: 0.00839414237634628 |bi: 0.015398123679915443
training time(min): 10.960571575164796
start training epoch: 73
epoch: 73 |loss: 0.9064488119329326 |cls: 0.4482344119314803 |mse: 0.008438005610514665 |bi: 0.015419785519043216
training time(min): 11.238055284818014
start training epoch: 74
epoch: 74 |loss: 0.9189528414572123 |cls: 0.4545055902271997 |mse: 0.008401441242313012 |bi: 0.015402217959490372
training time(min): 11.226771354675293
start training epoch: 75
epoch: 75 |loss: 0.9419913165620528 |cls: 0.46602228429401293 |mse: 0.008405243855122535 |bi: 0.015415039128129138
training time(min): 11.179340024789175
start training epoch: 76
epoch: 76 |loss: 0.9118193934555165 |cls: 0.4509285920066759 |mse: 0.008420862392085837 |bi: 0.01541349998296937
training time(min): 11.25321722428004
start training epoch: 77
epoch: 77 |loss: 0.943850597483106 |cls: 0.46694858037517406 |mse: 0.00841241122543579 |bi: 0.015410232143040048
training time(min): 11.153743227322897
start training epoch: 78
epoch: 78 |loss: 0.8452080203569494 |cls: 0.4176277395163197 |mse: 0.008411292414166383 |bi: 0.01541248401554185
training time(min): 11.225398031870524
start training epoch: 79
epoch: 79 |loss: 0.892972695408389 |cls: 0.44151072204113007 |mse: 0.008410106054725475 |bi: 0.015411437696457142
training time(min): 11.151951503753661
start training epoch: 80
epoch: 80 |loss: 0.7842040592804551 |cls: 0.3870863586489577 |mse: 0.008487191060339683 |bi: 0.015441538253071485
training time(min): 10.359919055302937
sample: 0
sample: 1
sample: 2
sample: 3
sample: 4
sample: 5
sample: 6
sample: 7
sample: 8
sample: 9
sample: 10
sample: 11
sample: 12
sample: 13
sample: 14
sample: 15
sample: 16
sample: 17
sample: 18
sample: 19
sample: 20
sample: 21
sample: 22
sample: 23
sample: 24
sample: 25
sample: 26
sample: 27
sample: 28
sample: 29
sample: 30
sample: 31
sample: 32
sample: 33
sample: 34
sample: 35
sample: 36
sample: 37
sample: 38
sample: 39
sample: 40
sample: 41
sample: 42
sample: 43
sample: 44
sample: 45
sample: 46
sample: 47
sample: 48
sample: 49
sample: 50
sample: 51
sample: 52
sample: 53
sample: 54
sample: 55
sample: 56
sample: 57
testing epoch: 80 Acc:0.4871
start training epoch: 81
epoch: 81 |loss: 0.79364771413384 |cls: 0.391854095767485 |mse: 0.008397505303946673 |bi: 0.015420179744978668
training time(min): 10.23144937356313
start training epoch: 82
epoch: 82 |loss: 0.8011048304033466 |cls: 0.3955651164287701 |mse: 0.008431380168985925 |bi: 0.015432174470333848
training time(min): 9.859903824329376
start training epoch: 83
epoch: 83 |loss: 0.7620109973067883 |cls: 0.3760302734444849 |mse: 0.008409124666286516 |bi: 0.015413219418405788
training time(min): 10.178993233044942
start training epoch: 84
epoch: 84 |loss: 0.8048178220342379 |cls: 0.3974304963630857 |mse: 0.008416150874836603 |bi: 0.015406789956614375
training time(min): 10.008852450052897
start training epoch: 85
epoch: 85 |loss: 0.752454415691318 |cls: 0.37124386109644547 |mse: 0.008423142033279873 |bi: 0.015435495388373965
training time(min): 10.174520301818848
start training epoch: 86
epoch: 86 |loss: 0.7479197101783939 |cls: 0.3689766432798933 |mse: 0.008424394582107197 |bi: 0.015420293446368305
training time(min): 10.053005190690358
start training epoch: 87
epoch: 87 |loss: 0.7136234587524086 |cls: 0.3518359882873483 |mse: 0.008410897362409742 |bi: 0.015405857313453453
training time(min): 10.54230234225591
start training epoch: 88
epoch: 88 |loss: 0.8157999336253852 |cls: 0.4029170891008107 |mse: 0.00842384389761719 |bi: 0.015419118230056483
training time(min): 10.038976049423217
start training epoch: 89
epoch: 89 |loss: 0.7872855344903655 |cls: 0.38867261391715147 |mse: 0.008399500984523911 |bi: 0.01540804856995237
training time(min): 10.05896846850713
start training epoch: 90
epoch: 90 |loss: 0.737918843049556 |cls: 0.36396267045347486 |mse: 0.00845022114845051 |bi: 0.015432803778821835
training time(min): 9.852651957670847
sample: 0
sample: 1
sample: 2
sample: 3
sample: 4
sample: 5
sample: 6
sample: 7
sample: 8
sample: 9
sample: 10
sample: 11
sample: 12
sample: 13
sample: 14
sample: 15
sample: 16
sample: 17
sample: 18
sample: 19
sample: 20
sample: 21
sample: 22
sample: 23
sample: 24
sample: 25
sample: 26
sample: 27
sample: 28
sample: 29
sample: 30
sample: 31
sample: 32
sample: 33
sample: 34
sample: 35
sample: 36
sample: 37
sample: 38
sample: 39
sample: 40
sample: 41
sample: 42
sample: 43
sample: 44
sample: 45
sample: 46
sample: 47
sample: 48
sample: 49
sample: 50
sample: 51
sample: 52
sample: 53
sample: 54
sample: 55
sample: 56
sample: 57
testing epoch: 90 Acc:0.4741
start training epoch: 91
epoch: 91 |loss: 0.7591257594758645 |cls: 0.37459141097497195 |mse: 0.008402430622481916 |bi: 0.01540507642130251
training time(min): 10.43006991147995
start training epoch: 92
epoch: 92 |loss: 0.7222498772316612 |cls: 0.3561360313833575 |mse: 0.008435015926806955 |bi: 0.015428004353452707
training time(min): 9.864858527978262
start training epoch: 93
epoch: 93 |loss: 0.7938052695826627 |cls: 0.39191917683638167 |mse: 0.008423519368079724 |bi: 0.01543395623593824
training time(min): 9.752082852522532
start training epoch: 94
epoch: 94 |loss: 0.7609600542346016 |cls: 0.37550910157733597 |mse: 0.008400917578910594 |bi: 0.015409291976538952
training time(min): 10.296697890758514
start training epoch: 95
epoch: 95 |loss: 0.7461509232816752 |cls: 0.36809688940411434 |mse: 0.008416144461079966 |bi: 0.015409997155074961
training time(min): 10.308491977055867
start training epoch: 96
epoch: 96 |loss: 0.7289914630237035 |cls: 0.359501212296891 |mse: 0.008445441771982587 |bi: 0.01543598820353509
training time(min): 9.844841368993123
start training epoch: 97
epoch: 97 |loss: 0.7473904978251085 |cls: 0.36871189168596175 |mse: 0.008424196768828551 |bi: 0.01542519145004917
training time(min): 10.157004141807557
start training epoch: 98
epoch: 98 |loss: 0.7238581335986964 |cls: 0.3569600852788426 |mse: 0.008396987410378642 |bi: 0.015409762021590723
training time(min): 9.082772870858511
start training epoch: 99
epoch: 99 |loss: 0.7116663542110473 |cls: 0.35084371609264053 |mse: 0.00843704775252263 |bi: 0.015418693641549908
training time(min): 8.697870087623595
start training epoch: 100
epoch: 100 |loss: 0.7913503519375809 |cls: 0.39068954206595663 |mse: 0.008429485760643729 |bi: 0.015417821778100915
training time(min): 9.258728281656902
sample: 0
sample: 1
sample: 2
sample: 3
sample: 4
sample: 5
sample: 6
sample: 7
sample: 8
sample: 9
sample: 10
sample: 11
sample: 12
sample: 13
sample: 14
sample: 15
sample: 16
sample: 17
sample: 18
sample: 19
sample: 20
sample: 21
sample: 22
sample: 23
sample: 24
sample: 25
sample: 26
sample: 27
sample: 28
sample: 29
sample: 30
sample: 31
sample: 32
sample: 33
sample: 34
sample: 35
sample: 36
sample: 37
sample: 38
sample: 39
sample: 40
sample: 41
sample: 42
sample: 43
sample: 44
sample: 45
sample: 46
sample: 47
sample: 48
sample: 49
sample: 50
sample: 51
sample: 52
sample: 53
sample: 54
sample: 55
sample: 56
sample: 57
testing epoch: 100 Acc:0.4569
done
