gumbel thresh: 0.505
mode: dy+bi+cl model path: ./ModelFile/crossView_NUCLA/Multi/dy+bi+cl/DIR-tenc-mean/ gpu: 4
is_clstoken  True
mean   False
seq_len  5
input projection present encoder:  4025
output projection present encoder:  4025
embed_dim:  8050
embed_proj_dim:  4025
ff_dim:  2048
num_heads:  7
num_layers:  2
dropout:  0.1
seq_len:  5
keys  odict_keys(['backbone.sparseCoding.rr', 'backbone.sparseCoding.theta', 'backbone.transformer_encoder.cls_token', 'backbone.transformer_encoder.input_layer.weight', 'backbone.transformer_encoder.input_layer.bias', 'backbone.transformer_encoder.output_layer.weight', 'backbone.transformer_encoder.output_layer.bias', 'backbone.transformer_encoder.pos_encoder.pe', 'backbone.transformer_encoder.encoder_layer.self_attn.in_proj_weight', 'backbone.transformer_encoder.encoder_layer.self_attn.in_proj_bias', 'backbone.transformer_encoder.encoder_layer.self_attn.out_proj.weight', 'backbone.transformer_encoder.encoder_layer.self_attn.out_proj.bias', 'backbone.transformer_encoder.encoder_layer.linear1.weight', 'backbone.transformer_encoder.encoder_layer.linear1.bias', 'backbone.transformer_encoder.encoder_layer.linear2.weight', 'backbone.transformer_encoder.encoder_layer.linear2.bias', 'backbone.transformer_encoder.encoder_layer.norm1.weight', 'backbone.transformer_encoder.encoder_layer.norm1.bias', 'backbone.transformer_encoder.encoder_layer.norm2.weight', 'backbone.transformer_encoder.encoder_layer.norm2.bias', 'backbone.transformer_encoder.transformer_encoder.layers.0.self_attn.in_proj_weight', 'backbone.transformer_encoder.transformer_encoder.layers.0.self_attn.in_proj_bias', 'backbone.transformer_encoder.transformer_encoder.layers.0.self_attn.out_proj.weight', 'backbone.transformer_encoder.transformer_encoder.layers.0.self_attn.out_proj.bias', 'backbone.transformer_encoder.transformer_encoder.layers.0.linear1.weight', 'backbone.transformer_encoder.transformer_encoder.layers.0.linear1.bias', 'backbone.transformer_encoder.transformer_encoder.layers.0.linear2.weight', 'backbone.transformer_encoder.transformer_encoder.layers.0.linear2.bias', 'backbone.transformer_encoder.transformer_encoder.layers.0.norm1.weight', 'backbone.transformer_encoder.transformer_encoder.layers.0.norm1.bias', 'backbone.transformer_encoder.transformer_encoder.layers.0.norm2.weight', 'backbone.transformer_encoder.transformer_encoder.layers.0.norm2.bias', 'backbone.transformer_encoder.transformer_encoder.layers.1.self_attn.in_proj_weight', 'backbone.transformer_encoder.transformer_encoder.layers.1.self_attn.in_proj_bias', 'backbone.transformer_encoder.transformer_encoder.layers.1.self_attn.out_proj.weight', 'backbone.transformer_encoder.transformer_encoder.layers.1.self_attn.out_proj.bias', 'backbone.transformer_encoder.transformer_encoder.layers.1.linear1.weight', 'backbone.transformer_encoder.transformer_encoder.layers.1.linear1.bias', 'backbone.transformer_encoder.transformer_encoder.layers.1.linear2.weight', 'backbone.transformer_encoder.transformer_encoder.layers.1.linear2.bias', 'backbone.transformer_encoder.transformer_encoder.layers.1.norm1.weight', 'backbone.transformer_encoder.transformer_encoder.layers.1.norm1.bias', 'backbone.transformer_encoder.transformer_encoder.layers.1.norm2.weight', 'backbone.transformer_encoder.transformer_encoder.layers.1.norm2.bias', 'backbone.Classifier.conv1.weight', 'backbone.Classifier.conv1.bias', 'backbone.Classifier.bn1.weight', 'backbone.Classifier.bn1.bias', 'backbone.Classifier.bn1.running_mean', 'backbone.Classifier.bn1.running_var', 'backbone.Classifier.bn1.num_batches_tracked', 'backbone.Classifier.conv2.weight', 'backbone.Classifier.conv2.bias', 'backbone.Classifier.bn2.weight', 'backbone.Classifier.bn2.bias', 'backbone.Classifier.bn2.running_mean', 'backbone.Classifier.bn2.running_var', 'backbone.Classifier.bn2.num_batches_tracked', 'backbone.Classifier.conv3.weight', 'backbone.Classifier.conv3.bias', 'backbone.Classifier.bn3.weight', 'backbone.Classifier.bn3.bias', 'backbone.Classifier.bn3.running_mean', 'backbone.Classifier.bn3.running_var', 'backbone.Classifier.bn3.num_batches_tracked', 'backbone.Classifier.conv4.weight', 'backbone.Classifier.conv4.bias', 'backbone.Classifier.bn4.weight', 'backbone.Classifier.bn4.bias', 'backbone.Classifier.bn4.running_mean', 'backbone.Classifier.bn4.running_var', 'backbone.Classifier.bn4.num_batches_tracked', 'backbone.Classifier.conv5.weight', 'backbone.Classifier.conv5.bias', 'backbone.Classifier.bn5.weight', 'backbone.Classifier.bn5.bias', 'backbone.Classifier.bn5.running_mean', 'backbone.Classifier.bn5.running_var', 'backbone.Classifier.bn5.num_batches_tracked', 'backbone.Classifier.conv6.weight', 'backbone.Classifier.conv6.bias', 'backbone.Classifier.bn6.weight', 'backbone.Classifier.bn6.bias', 'backbone.Classifier.bn6.running_mean', 'backbone.Classifier.bn6.running_var', 'backbone.Classifier.bn6.num_batches_tracked', 'backbone.Classifier.fc.weight', 'backbone.Classifier.fc.bias', 'backbone.Classifier.fc2.weight', 'backbone.Classifier.fc2.bias', 'backbone.Classifier.fc3.weight', 'backbone.Classifier.fc3.bias', 'backbone.Classifier.cls.0.weight', 'backbone.Classifier.cls.0.bias', 'proj.weight', 'proj.bias'])
cls token  tensor([[[ 0.0742, -0.6031, -0.0750,  ..., -1.3075,  0.4966, -0.7540]]],
       device='cuda:4')
rr  tensor([1.0738, 0.9827, 0.9756, 1.1247, 0.9363, 1.0295, 1.0171, 0.8772, 1.1414,
        0.8764, 1.0417, 1.0411, 0.9704, 0.8741, 1.0286, 0.8505, 1.1323, 1.0011,
        0.8609, 0.8905, 0.9876, 1.0116, 0.9802, 0.8808, 1.0316, 1.0559, 1.1463,
        1.0903, 0.9350, 1.0455, 0.9752, 0.8884, 0.8512, 1.0178, 1.0932, 1.1434,
        1.1080, 0.9231, 1.1499, 0.9333, 0.9124, 0.8827, 1.0343, 1.0172, 0.8646,
        1.1115, 0.8968, 1.1214, 1.1036, 1.0951, 0.9496, 1.1026, 1.0418, 0.9571,
        1.0756, 1.0673, 0.8579, 1.1263, 1.0073, 1.1280, 1.0781, 0.8988, 0.9347,
        1.0849, 1.0072, 0.9259, 1.0844, 0.8510, 0.8943, 0.8692, 1.0417, 1.1310,
        0.9874, 0.8866, 0.9528, 0.9757, 0.9415, 1.1430, 0.9416, 1.1242],
       device='cuda:4')
theta  tensor([1.3939, 2.4549, 1.6436, 1.5352, 0.7960, 3.0716, 2.6964, 2.0584, 0.7135,
        2.3078, 1.8680, 1.5814, 2.5930, 2.1385, 0.6050, 1.4292, 1.4744, 0.3818,
        2.0396, 2.8664, 0.4994, 2.8990, 1.4337, 2.9520, 2.1435, 1.2748, 0.3789,
        2.3218, 1.4669, 1.7877, 1.0691, 2.8505, 0.6513, 2.9708, 2.0885, 3.0277,
        1.2882, 1.7110, 2.6468, 2.2400, 1.1219, 0.2007, 0.5942, 0.7402, 2.4891,
        0.8861, 1.3891, 2.8232, 2.3094, 0.7382, 2.3175, 1.3819, 0.8533, 0.4777,
        3.0391, 1.8822, 1.2420, 3.1185, 0.1625, 0.9867, 1.3501, 2.3475, 1.5333,
        1.8721, 1.7133, 1.3431, 0.9326, 3.1381, 1.3014, 2.0869, 1.4987, 1.2876,
        2.5508, 0.4858, 1.6475, 0.5840, 1.7340, 1.2651, 3.0234, 2.8446],
       device='cuda:4')
cls  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:4')
pre_train: /home/balaji/crossView_CL/ModelFile/crossView_NUCLA/Multi/dy+bi+cl/dir-tenc-cl-token/120.pth
loaded cls token  tensor([[[ 0.0674, -0.5496, -0.0684,  ..., -1.1914,  0.4515, -0.6864]]],
       device='cuda:4')
loaded rr  tensor([1.0599, 0.9743, 0.9663, 1.0703, 0.9268, 1.0206, 1.0072, 0.8694, 1.0412,
        0.8684, 1.0341, 1.0315, 0.9607, 0.8662, 0.9808, 0.8436, 1.0713, 0.9619,
        0.8533, 0.8830, 0.9458, 1.0024, 0.9725, 0.8735, 1.0197, 1.0501, 0.9950,
        1.0803, 0.9276, 1.0258, 0.9668, 0.8809, 0.8451, 1.0097, 1.0486, 1.0795,
        1.0817, 0.9156, 1.0775, 0.9241, 0.9034, 0.9111, 0.9747, 1.0095, 0.8571,
        1.0324, 0.8895, 1.0864, 1.0823, 1.0429, 0.9402, 1.0635, 0.9906, 0.9406,
        1.0659, 1.0572, 0.8507, 1.0796, 0.9868, 1.0320, 1.0559, 0.8908, 0.9269,
        1.0619, 0.9963, 0.9183, 1.0403, 0.8440, 0.8867, 0.8616, 1.0331, 1.0858,
        0.9757, 0.8722, 0.9442, 0.9596, 0.9335, 1.0722, 0.9340, 1.0885],
       device='cuda:4')
loaded theta  tensor([1.3831, 2.4351, 1.6302, 1.5173, 0.7894, 3.0460, 2.6738, 2.0410, 0.7377,
        2.2888, 1.8529, 1.5642, 2.5720, 2.1206, 0.6029, 1.4175, 1.4665, 0.3462,
        2.0224, 2.8426, 0.5185, 2.8750, 1.4217, 2.9278, 2.1216, 1.2670, 0.3556,
        2.2961, 1.4546, 1.7748, 1.0654, 2.8268, 0.6468, 2.9488, 2.0768, 3.0085,
        1.2792, 1.6970, 2.6287, 2.2216, 1.1125, 0.2004, 0.5884, 0.7404, 2.4684,
        0.9092, 1.3778, 2.8066, 2.2928, 0.7396, 2.2984, 1.3781, 0.8437, 0.4658,
        3.0172, 1.8672, 1.2320, 3.0912, 0.1108, 0.9424, 1.3398, 2.3283, 1.5204,
        1.8600, 1.6995, 1.3323, 0.9231, 3.1122, 1.2911, 2.0694, 1.4857, 1.2852,
        2.5297, 0.4884, 1.6341, 0.5822, 1.7197, 1.2677, 2.9984, 2.8182],
       device='cuda:4')
cls  tensor([0.8484, 0.8276, 0.8372, 0.8752, 0.8003, 0.8422, 0.8400, 0.8025, 0.8336,
        0.8346, 0.8275, 0.8354, 0.8207, 0.8300, 0.8455, 0.8484, 0.8419, 0.8373,
        0.8640, 0.8611, 0.8521, 0.8268, 0.8461, 0.8159, 0.8278, 0.8416, 0.8396,
        0.8577, 0.8842, 0.8266, 0.8257, 0.8401, 0.8275, 0.8336, 0.8590, 0.8388,
        0.8648, 0.8448, 0.8301, 0.8474, 0.8297, 0.8502, 0.8351, 0.8129, 0.8601,
        0.8431, 0.8398, 0.8383, 0.8129, 0.8389, 0.8276, 0.8552, 0.8405, 0.8391,
        0.8262, 0.8229, 0.8610, 0.8466, 0.8455, 0.8313, 0.8358, 0.8332, 0.8443,
        0.8417, 0.8318, 0.8266, 0.8520, 0.8360, 0.8622, 0.8336, 0.8211, 0.8570,
        0.8307, 0.8304, 0.8326, 0.8367, 0.8488, 0.8263, 0.8574, 0.8394, 0.8331,
        0.8383, 0.8375, 0.8452, 0.8255, 0.8335, 0.8600, 0.8532, 0.8550, 0.8401,
        0.8469, 0.8434, 0.8370, 0.8422, 0.8549, 0.8165, 0.8297, 0.8492, 0.8481,
        0.8370, 0.8270, 0.8242, 0.8144, 0.8534, 0.8111, 0.8534, 0.8233, 0.8434,
        0.8216, 0.8480, 0.8387, 0.8464, 0.8336, 0.8418, 0.8317, 0.8056, 0.8312,
        0.8338, 0.8207, 0.8292, 0.8315, 0.8279, 0.8329, 0.8187, 0.8452, 0.8394,
        0.8404, 0.8417, 0.8096, 0.8498, 0.8227, 0.8281, 0.8363, 0.8361, 0.8407,
        0.8240, 0.8332, 0.8278, 0.8415, 0.8494, 0.8275, 0.8461, 0.8340, 0.8440,
        0.8218, 0.8085, 0.8310, 0.8486, 0.8451, 0.8309, 0.8538, 0.8352, 0.8496,
        0.8560, 0.8276, 0.8236, 0.8365, 0.8185, 0.8212, 0.8150, 0.8347, 0.8489,
        0.8335, 0.8617, 0.8418, 0.8335, 0.8579, 0.8352, 0.8452, 0.8340, 0.8284,
        0.8313, 0.8423, 0.8578, 0.8420, 0.8351, 0.8170, 0.8490, 0.8330, 0.8241,
        0.8496, 0.8257, 0.8355, 0.8500, 0.8534, 0.8130, 0.8522, 0.8536, 0.8390,
        0.8613, 0.8305, 0.8506, 0.8489, 0.8053, 0.8212, 0.8279, 0.8258, 0.8264,
        0.8263, 0.8268, 0.8457, 0.8414, 0.8502, 0.8416, 0.8488, 0.8273, 0.8406,
        0.8784, 0.8188, 0.8348, 0.8421, 0.8499, 0.8629, 0.8350, 0.8446, 0.8293,
        0.8497, 0.8409, 0.8441, 0.8485, 0.8382, 0.8378, 0.8168, 0.8481, 0.8406,
        0.8602, 0.8272, 0.8444, 0.8236, 0.8443, 0.8454, 0.8406, 0.8183, 0.8168,
        0.8403, 0.8415, 0.8256, 0.8291, 0.8284, 0.8586, 0.8638, 0.8456, 0.8423,
        0.8073, 0.8294, 0.8220, 0.8267, 0.8396, 0.8699, 0.8147, 0.8610, 0.8304,
        0.8171, 0.8486, 0.8112, 0.8362], device='cuda:4')
p  backbone.sparseCoding.rr False
p  backbone.sparseCoding.theta False
p  backbone.transformer_encoder.cls_token False
p  backbone.transformer_encoder.input_layer.weight False
p  backbone.transformer_encoder.input_layer.bias False
p  backbone.transformer_encoder.output_layer.weight False
p  backbone.transformer_encoder.output_layer.bias False
p  backbone.transformer_encoder.encoder_layer.self_attn.in_proj_weight False
p  backbone.transformer_encoder.encoder_layer.self_attn.in_proj_bias False
p  backbone.transformer_encoder.encoder_layer.self_attn.out_proj.weight False
p  backbone.transformer_encoder.encoder_layer.self_attn.out_proj.bias False
p  backbone.transformer_encoder.encoder_layer.linear1.weight False
p  backbone.transformer_encoder.encoder_layer.linear1.bias False
p  backbone.transformer_encoder.encoder_layer.linear2.weight False
p  backbone.transformer_encoder.encoder_layer.linear2.bias False
p  backbone.transformer_encoder.encoder_layer.norm1.weight False
p  backbone.transformer_encoder.encoder_layer.norm1.bias False
p  backbone.transformer_encoder.encoder_layer.norm2.weight False
p  backbone.transformer_encoder.encoder_layer.norm2.bias False
p  backbone.transformer_encoder.transformer_encoder.layers.0.self_attn.in_proj_weight False
p  backbone.transformer_encoder.transformer_encoder.layers.0.self_attn.in_proj_bias False
p  backbone.transformer_encoder.transformer_encoder.layers.0.self_attn.out_proj.weight False
p  backbone.transformer_encoder.transformer_encoder.layers.0.self_attn.out_proj.bias False
p  backbone.transformer_encoder.transformer_encoder.layers.0.linear1.weight False
p  backbone.transformer_encoder.transformer_encoder.layers.0.linear1.bias False
p  backbone.transformer_encoder.transformer_encoder.layers.0.linear2.weight False
p  backbone.transformer_encoder.transformer_encoder.layers.0.linear2.bias False
p  backbone.transformer_encoder.transformer_encoder.layers.0.norm1.weight False
p  backbone.transformer_encoder.transformer_encoder.layers.0.norm1.bias False
p  backbone.transformer_encoder.transformer_encoder.layers.0.norm2.weight False
p  backbone.transformer_encoder.transformer_encoder.layers.0.norm2.bias False
p  backbone.transformer_encoder.transformer_encoder.layers.1.self_attn.in_proj_weight False
p  backbone.transformer_encoder.transformer_encoder.layers.1.self_attn.in_proj_bias False
p  backbone.transformer_encoder.transformer_encoder.layers.1.self_attn.out_proj.weight False
p  backbone.transformer_encoder.transformer_encoder.layers.1.self_attn.out_proj.bias False
p  backbone.transformer_encoder.transformer_encoder.layers.1.linear1.weight False
p  backbone.transformer_encoder.transformer_encoder.layers.1.linear1.bias False
p  backbone.transformer_encoder.transformer_encoder.layers.1.linear2.weight False
p  backbone.transformer_encoder.transformer_encoder.layers.1.linear2.bias False
p  backbone.transformer_encoder.transformer_encoder.layers.1.norm1.weight False
p  backbone.transformer_encoder.transformer_encoder.layers.1.norm1.bias False
p  backbone.transformer_encoder.transformer_encoder.layers.1.norm2.weight False
p  backbone.transformer_encoder.transformer_encoder.layers.1.norm2.bias False
p  backbone.Classifier.conv1.weight False
p  backbone.Classifier.conv1.bias False
p  backbone.Classifier.bn1.weight False
p  backbone.Classifier.bn1.bias False
p  backbone.Classifier.conv2.weight False
p  backbone.Classifier.conv2.bias False
p  backbone.Classifier.bn2.weight False
p  backbone.Classifier.bn2.bias False
p  backbone.Classifier.conv3.weight False
p  backbone.Classifier.conv3.bias False
p  backbone.Classifier.bn3.weight False
p  backbone.Classifier.bn3.bias False
p  backbone.Classifier.conv4.weight False
p  backbone.Classifier.conv4.bias False
p  backbone.Classifier.bn4.weight False
p  backbone.Classifier.bn4.bias False
p  backbone.Classifier.conv5.weight False
p  backbone.Classifier.conv5.bias False
p  backbone.Classifier.bn5.weight False
p  backbone.Classifier.bn5.bias False
p  backbone.Classifier.conv6.weight False
p  backbone.Classifier.conv6.bias False
p  backbone.Classifier.bn6.weight False
p  backbone.Classifier.bn6.bias False
p  backbone.Classifier.fc.weight False
p  backbone.Classifier.fc.bias False
p  backbone.Classifier.fc2.weight False
p  backbone.Classifier.fc2.bias False
p  backbone.Classifier.fc3.weight False
p  backbone.Classifier.fc3.bias False
p  backbone.Classifier.cls.0.weight True
p  backbone.Classifier.cls.0.bias True
p  proj.weight False
p  proj.bias False
cls token  tensor([[[ 0.0674, -0.5496, -0.0684,  ..., -1.1914,  0.4515, -0.6864]]],
       device='cuda:4')
after rr  tensor([1.0599, 0.9743, 0.9663, 1.0703, 0.9268, 1.0206, 1.0072, 0.8694, 1.0412,
        0.8684, 1.0341, 1.0315, 0.9607, 0.8662, 0.9808, 0.8436, 1.0713, 0.9619,
        0.8533, 0.8830, 0.9458, 1.0024, 0.9725, 0.8735, 1.0197, 1.0501, 0.9950,
        1.0803, 0.9276, 1.0258, 0.9668, 0.8809, 0.8451, 1.0097, 1.0486, 1.0795,
        1.0817, 0.9156, 1.0775, 0.9241, 0.9034, 0.9111, 0.9747, 1.0095, 0.8571,
        1.0324, 0.8895, 1.0864, 1.0823, 1.0429, 0.9402, 1.0635, 0.9906, 0.9406,
        1.0659, 1.0572, 0.8507, 1.0796, 0.9868, 1.0320, 1.0559, 0.8908, 0.9269,
        1.0619, 0.9963, 0.9183, 1.0403, 0.8440, 0.8867, 0.8616, 1.0331, 1.0858,
        0.9757, 0.8722, 0.9442, 0.9596, 0.9335, 1.0722, 0.9340, 1.0885],
       device='cuda:4')
after theta  tensor([1.3831, 2.4351, 1.6302, 1.5173, 0.7894, 3.0460, 2.6738, 2.0410, 0.7377,
        2.2888, 1.8529, 1.5642, 2.5720, 2.1206, 0.6029, 1.4175, 1.4665, 0.3462,
        2.0224, 2.8426, 0.5185, 2.8750, 1.4217, 2.9278, 2.1216, 1.2670, 0.3556,
        2.2961, 1.4546, 1.7748, 1.0654, 2.8268, 0.6468, 2.9488, 2.0768, 3.0085,
        1.2792, 1.6970, 2.6287, 2.2216, 1.1125, 0.2004, 0.5884, 0.7404, 2.4684,
        0.9092, 1.3778, 2.8066, 2.2928, 0.7396, 2.2984, 1.3781, 0.8437, 0.4658,
        3.0172, 1.8672, 1.2320, 3.0912, 0.1108, 0.9424, 1.3398, 2.3283, 1.5204,
        1.8600, 1.6995, 1.3323, 0.9231, 3.1122, 1.2911, 2.0694, 1.4857, 1.2852,
        2.5297, 0.4884, 1.6341, 0.5822, 1.7197, 1.2677, 2.9984, 2.8182],
       device='cuda:4')
cls  tensor([0.8484, 0.8276, 0.8372, 0.8752, 0.8003, 0.8422, 0.8400, 0.8025, 0.8336,
        0.8346, 0.8275, 0.8354, 0.8207, 0.8300, 0.8455, 0.8484, 0.8419, 0.8373,
        0.8640, 0.8611, 0.8521, 0.8268, 0.8461, 0.8159, 0.8278, 0.8416, 0.8396,
        0.8577, 0.8842, 0.8266, 0.8257, 0.8401, 0.8275, 0.8336, 0.8590, 0.8388,
        0.8648, 0.8448, 0.8301, 0.8474, 0.8297, 0.8502, 0.8351, 0.8129, 0.8601,
        0.8431, 0.8398, 0.8383, 0.8129, 0.8389, 0.8276, 0.8552, 0.8405, 0.8391,
        0.8262, 0.8229, 0.8610, 0.8466, 0.8455, 0.8313, 0.8358, 0.8332, 0.8443,
        0.8417, 0.8318, 0.8266, 0.8520, 0.8360, 0.8622, 0.8336, 0.8211, 0.8570,
        0.8307, 0.8304, 0.8326, 0.8367, 0.8488, 0.8263, 0.8574, 0.8394, 0.8331,
        0.8383, 0.8375, 0.8452, 0.8255, 0.8335, 0.8600, 0.8532, 0.8550, 0.8401,
        0.8469, 0.8434, 0.8370, 0.8422, 0.8549, 0.8165, 0.8297, 0.8492, 0.8481,
        0.8370, 0.8270, 0.8242, 0.8144, 0.8534, 0.8111, 0.8534, 0.8233, 0.8434,
        0.8216, 0.8480, 0.8387, 0.8464, 0.8336, 0.8418, 0.8317, 0.8056, 0.8312,
        0.8338, 0.8207, 0.8292, 0.8315, 0.8279, 0.8329, 0.8187, 0.8452, 0.8394,
        0.8404, 0.8417, 0.8096, 0.8498, 0.8227, 0.8281, 0.8363, 0.8361, 0.8407,
        0.8240, 0.8332, 0.8278, 0.8415, 0.8494, 0.8275, 0.8461, 0.8340, 0.8440,
        0.8218, 0.8085, 0.8310, 0.8486, 0.8451, 0.8309, 0.8538, 0.8352, 0.8496,
        0.8560, 0.8276, 0.8236, 0.8365, 0.8185, 0.8212, 0.8150, 0.8347, 0.8489,
        0.8335, 0.8617, 0.8418, 0.8335, 0.8579, 0.8352, 0.8452, 0.8340, 0.8284,
        0.8313, 0.8423, 0.8578, 0.8420, 0.8351, 0.8170, 0.8490, 0.8330, 0.8241,
        0.8496, 0.8257, 0.8355, 0.8500, 0.8534, 0.8130, 0.8522, 0.8536, 0.8390,
        0.8613, 0.8305, 0.8506, 0.8489, 0.8053, 0.8212, 0.8279, 0.8258, 0.8264,
        0.8263, 0.8268, 0.8457, 0.8414, 0.8502, 0.8416, 0.8488, 0.8273, 0.8406,
        0.8784, 0.8188, 0.8348, 0.8421, 0.8499, 0.8629, 0.8350, 0.8446, 0.8293,
        0.8497, 0.8409, 0.8441, 0.8485, 0.8382, 0.8378, 0.8168, 0.8481, 0.8406,
        0.8602, 0.8272, 0.8444, 0.8236, 0.8443, 0.8454, 0.8406, 0.8183, 0.8168,
        0.8403, 0.8415, 0.8256, 0.8291, 0.8284, 0.8586, 0.8638, 0.8456, 0.8423,
        0.8073, 0.8294, 0.8220, 0.8267, 0.8396, 0.8699, 0.8147, 0.8610, 0.8304,
        0.8171, 0.8486, 0.8112, 0.8362], device='cuda:4')
optimizer  SGD (
Parameter Group 0
    dampening: 0
    lr: 0.001
    momentum: 0.9
    nesterov: False
    weight_decay: 0.001
)
start training epoch: 0
epoch: 0 |loss: 4.391494584269822 |cls: 2.1907709455117583 |mse: 0.00841281969769625 |bi: 0.015398775747598847
training time(min): 8.573435457547506
sample: 0
sample: 1
sample: 2
sample: 3
sample: 4
sample: 5
sample: 6
sample: 7
sample: 8
sample: 9
sample: 10
sample: 11
sample: 12
sample: 13
sample: 14
sample: 15
sample: 16
sample: 17
sample: 18
sample: 19
sample: 20
sample: 21
sample: 22
sample: 23
sample: 24
sample: 25
sample: 26
sample: 27
sample: 28
sample: 29
sample: 30
sample: 31
sample: 32
sample: 33
sample: 34
sample: 35
sample: 36
sample: 37
sample: 38
sample: 39
sample: 40
sample: 41
sample: 42
sample: 43
sample: 44
sample: 45
sample: 46
sample: 47
sample: 48
sample: 49
sample: 50
sample: 51
sample: 52
sample: 53
sample: 54
sample: 55
sample: 56
sample: 57
testing epoch: 0 Acc:0.1746
start training epoch: 1
epoch: 1 |loss: 4.083542823791504 |cls: 2.0367981111630797 |mse: 0.008405254935496487 |bi: 0.01541352273125085
training time(min): 8.718528016408284
start training epoch: 2
epoch: 2 |loss: 4.00172452442348 |cls: 1.9958699606359005 |mse: 0.008442441730949213 |bi: 0.015421658223203849
training time(min): 9.148417031764984
start training epoch: 3
epoch: 3 |loss: 4.004532513674349 |cls: 1.9972854796797037 |mse: 0.008419482168392278 |bi: 0.015420543721120339
training time(min): 8.527534584204355
start training epoch: 4
epoch: 4 |loss: 3.937499728053808 |cls: 1.963763292413205 |mse: 0.008430798105109716 |bi: 0.015423341443238314
training time(min): 6.564434440930684
start training epoch: 5
epoch: 5 |loss: 3.8799251364544034 |cls: 1.9349862809758633 |mse: 0.00841193831183773 |bi: 0.0154064487433061
training time(min): 7.8330658912658695
start training epoch: 6
epoch: 6 |loss: 3.9506189804524183 |cls: 1.970333341974765 |mse: 0.008410673684920766 |bi: 0.015416214318975108
training time(min): 7.907125131289164
start training epoch: 7
epoch: 7 |loss: 3.882868685759604 |cls: 1.9364459747448564 |mse: 0.008434230594502878 |bi: 0.015424979133968009
training time(min): 7.390884574254354
start training epoch: 8
epoch: 8 |loss: 3.938424495048821 |cls: 1.9642275921069086 |mse: 0.00842675822059391 |bi: 0.015425517445692094
training time(min): 7.54860432545344
start training epoch: 9
epoch: 9 |loss: 3.931058186106384 |cls: 1.960544541478157 |mse: 0.008428035258475575 |bi: 0.015410543026519008
training time(min): 7.528285264968872
start training epoch: 10
epoch: 10 |loss: 3.931932049803436 |cls: 1.9609719263389707 |mse: 0.008443757333225221 |bi: 0.015444442131411051
training time(min): 7.052347187201182
start training epoch: 11
epoch: 11 |loss: 3.9041732540354133 |cls: 1.947117700241506 |mse: 0.008398345123168838 |bi: 0.015395174297736958
training time(min): 6.648743673165639
start training epoch: 12
epoch: 12 |loss: 3.916521363891661 |cls: 1.9532804237678647 |mse: 0.00842047483092756 |bi: 0.01540045891306363
training time(min): 6.572276671727498
start training epoch: 13
epoch: 13 |loss: 3.885813795030117 |cls: 1.9379275366663933 |mse: 0.008416247328568716 |bi: 0.015424607641762123
training time(min): 6.812196540832519
start training epoch: 14
epoch: 14 |loss: 3.854590706527233 |cls: 1.922321256250143 |mse: 0.008407577812249656 |bi: 0.015406130263727391
training time(min): 7.437284350395203
start training epoch: 15
epoch: 15 |loss: 3.8424558583647013 |cls: 1.9162514791823924 |mse: 0.008410559734329581 |bi: 0.015423500659380807
training time(min): 7.436282853285472
start training epoch: 16
epoch: 16 |loss: 3.822454766370356 |cls: 1.9062271257862449 |mse: 0.008458097247057594 |bi: 0.015424076893395977
training time(min): 7.262926165262858
start training epoch: 17
epoch: 17 |loss: 3.861086457967758 |cls: 1.925552628468722 |mse: 0.008438759005002794 |bi: 0.015424418059410527
training time(min): 7.228761124610901
start training epoch: 18
epoch: 18 |loss: 3.853545225225389 |cls: 1.9218053333461285 |mse: 0.008394893059630704 |bi: 0.01539681952635874
training time(min): 7.56812983751297
start training epoch: 19
epoch: 19 |loss: 3.8263724111020565 |cls: 1.9082059324719012 |mse: 0.008419934869380086 |bi: 0.01540612270400743
training time(min): 7.533674379189809
start training epoch: 20
epoch: 20 |loss: 3.8167519737035036 |cls: 1.903391873696819 |mse: 0.008425048838034854 |bi: 0.015431954634550493
training time(min): 7.701096967856089
sample: 0
sample: 1
sample: 2
sample: 3
sample: 4
sample: 5
sample: 6
sample: 7
sample: 8
sample: 9
sample: 10
sample: 11
sample: 12
sample: 13
sample: 14
sample: 15
sample: 16
sample: 17
sample: 18
sample: 19
sample: 20
sample: 21
sample: 22
sample: 23
sample: 24
sample: 25
sample: 26
sample: 27
sample: 28
sample: 29
sample: 30
sample: 31
sample: 32
sample: 33
sample: 34
sample: 35
sample: 36
sample: 37
sample: 38
sample: 39
sample: 40
sample: 41
sample: 42
sample: 43
sample: 44
sample: 45
sample: 46
sample: 47
sample: 48
sample: 49
sample: 50
sample: 51
sample: 52
sample: 53
sample: 54
sample: 55
sample: 56
sample: 57
testing epoch: 20 Acc:0.1853
start training epoch: 21
epoch: 21 |loss: 3.792399439960718 |cls: 1.8912065676413476 |mse: 0.008442982913038577 |bi: 0.015433311753440648
training time(min): 7.487346363067627
start training epoch: 22
epoch: 22 |loss: 3.887685613706708 |cls: 1.9388435583095998 |mse: 0.008454192669887561 |bi: 0.015442994015756994
training time(min): 7.345912102858225
start training epoch: 23
epoch: 23 |loss: 3.848013963084668 |cls: 1.919035560451448 |mse: 0.008402093128097476 |bi: 0.015407434333610581
training time(min): 7.429380873839061
start training epoch: 24
epoch: 24 |loss: 3.8393538165837526 |cls: 1.9147038329392672 |mse: 0.008404247246289742 |bi: 0.015419042440043995
training time(min): 7.331519015630087
start training epoch: 25
epoch: 25 |loss: 3.873047672212124 |cls: 1.9315410293638706 |mse: 0.008423917724940111 |bi: 0.015416957401612308
training time(min): 7.553120088577271
start training epoch: 26
epoch: 26 |loss: 3.8300173627212644 |cls: 1.9100170815363526 |mse: 0.008438906068477081 |bi: 0.01544278168148594
training time(min): 7.594330171744029
start training epoch: 27
epoch: 27 |loss: 3.8861389844678342 |cls: 1.9380881239194423 |mse: 0.008420239097176818 |bi: 0.015424691016960423
training time(min): 7.334184269110362
start training epoch: 28
epoch: 28 |loss: 3.922221719287336 |cls: 1.956132029183209 |mse: 0.00841638876045181 |bi: 0.015412673576065572
training time(min): 7.293923123677572
start training epoch: 29
epoch: 29 |loss: 3.8387275468558073 |cls: 1.9143903185613453 |mse: 0.00840784048432397 |bi: 0.015390852513519349
training time(min): 7.398030217488607
start training epoch: 30
epoch: 30 |loss: 3.8790416377596557 |cls: 1.9345389981754124 |mse: 0.008420656087764655 |bi: 0.015429907449288294
training time(min): 7.354328676064809
start training epoch: 31
epoch: 31 |loss: 3.8368169171735644 |cls: 1.9134106133133173 |mse: 0.008451803138086689 |bi: 0.015438846665347228
training time(min): 7.46484610637029
start training epoch: 32
