gumbel thresh: 0.505
mode: dy+bi+cl model path: ./ModelFile/crossView_NUCLA/Multi/dy+bi+cl/DIR-tenc-mean-nf-cl1/ gpu: 5
is_clstoken  True
mean   True
seq_len  5
input projection present encoder:  4025
output projection present encoder:  4025
embed_dim:  8050
embed_proj_dim:  4025
ff_dim:  2048
num_heads:  7
num_layers:  2
dropout:  0.1
seq_len:  5
keys  odict_keys(['backbone.sparseCoding.rr', 'backbone.sparseCoding.theta', 'backbone.transformer_encoder.cls_token', 'backbone.transformer_encoder.input_layer.weight', 'backbone.transformer_encoder.input_layer.bias', 'backbone.transformer_encoder.output_layer.weight', 'backbone.transformer_encoder.output_layer.bias', 'backbone.transformer_encoder.pos_encoder.pe', 'backbone.transformer_encoder.encoder_layer.self_attn.in_proj_weight', 'backbone.transformer_encoder.encoder_layer.self_attn.in_proj_bias', 'backbone.transformer_encoder.encoder_layer.self_attn.out_proj.weight', 'backbone.transformer_encoder.encoder_layer.self_attn.out_proj.bias', 'backbone.transformer_encoder.encoder_layer.linear1.weight', 'backbone.transformer_encoder.encoder_layer.linear1.bias', 'backbone.transformer_encoder.encoder_layer.linear2.weight', 'backbone.transformer_encoder.encoder_layer.linear2.bias', 'backbone.transformer_encoder.encoder_layer.norm1.weight', 'backbone.transformer_encoder.encoder_layer.norm1.bias', 'backbone.transformer_encoder.encoder_layer.norm2.weight', 'backbone.transformer_encoder.encoder_layer.norm2.bias', 'backbone.transformer_encoder.transformer_encoder.layers.0.self_attn.in_proj_weight', 'backbone.transformer_encoder.transformer_encoder.layers.0.self_attn.in_proj_bias', 'backbone.transformer_encoder.transformer_encoder.layers.0.self_attn.out_proj.weight', 'backbone.transformer_encoder.transformer_encoder.layers.0.self_attn.out_proj.bias', 'backbone.transformer_encoder.transformer_encoder.layers.0.linear1.weight', 'backbone.transformer_encoder.transformer_encoder.layers.0.linear1.bias', 'backbone.transformer_encoder.transformer_encoder.layers.0.linear2.weight', 'backbone.transformer_encoder.transformer_encoder.layers.0.linear2.bias', 'backbone.transformer_encoder.transformer_encoder.layers.0.norm1.weight', 'backbone.transformer_encoder.transformer_encoder.layers.0.norm1.bias', 'backbone.transformer_encoder.transformer_encoder.layers.0.norm2.weight', 'backbone.transformer_encoder.transformer_encoder.layers.0.norm2.bias', 'backbone.transformer_encoder.transformer_encoder.layers.1.self_attn.in_proj_weight', 'backbone.transformer_encoder.transformer_encoder.layers.1.self_attn.in_proj_bias', 'backbone.transformer_encoder.transformer_encoder.layers.1.self_attn.out_proj.weight', 'backbone.transformer_encoder.transformer_encoder.layers.1.self_attn.out_proj.bias', 'backbone.transformer_encoder.transformer_encoder.layers.1.linear1.weight', 'backbone.transformer_encoder.transformer_encoder.layers.1.linear1.bias', 'backbone.transformer_encoder.transformer_encoder.layers.1.linear2.weight', 'backbone.transformer_encoder.transformer_encoder.layers.1.linear2.bias', 'backbone.transformer_encoder.transformer_encoder.layers.1.norm1.weight', 'backbone.transformer_encoder.transformer_encoder.layers.1.norm1.bias', 'backbone.transformer_encoder.transformer_encoder.layers.1.norm2.weight', 'backbone.transformer_encoder.transformer_encoder.layers.1.norm2.bias', 'backbone.Classifier.conv1.weight', 'backbone.Classifier.conv1.bias', 'backbone.Classifier.bn1.weight', 'backbone.Classifier.bn1.bias', 'backbone.Classifier.bn1.running_mean', 'backbone.Classifier.bn1.running_var', 'backbone.Classifier.bn1.num_batches_tracked', 'backbone.Classifier.conv2.weight', 'backbone.Classifier.conv2.bias', 'backbone.Classifier.bn2.weight', 'backbone.Classifier.bn2.bias', 'backbone.Classifier.bn2.running_mean', 'backbone.Classifier.bn2.running_var', 'backbone.Classifier.bn2.num_batches_tracked', 'backbone.Classifier.conv3.weight', 'backbone.Classifier.conv3.bias', 'backbone.Classifier.bn3.weight', 'backbone.Classifier.bn3.bias', 'backbone.Classifier.bn3.running_mean', 'backbone.Classifier.bn3.running_var', 'backbone.Classifier.bn3.num_batches_tracked', 'backbone.Classifier.conv4.weight', 'backbone.Classifier.conv4.bias', 'backbone.Classifier.bn4.weight', 'backbone.Classifier.bn4.bias', 'backbone.Classifier.bn4.running_mean', 'backbone.Classifier.bn4.running_var', 'backbone.Classifier.bn4.num_batches_tracked', 'backbone.Classifier.conv5.weight', 'backbone.Classifier.conv5.bias', 'backbone.Classifier.bn5.weight', 'backbone.Classifier.bn5.bias', 'backbone.Classifier.bn5.running_mean', 'backbone.Classifier.bn5.running_var', 'backbone.Classifier.bn5.num_batches_tracked', 'backbone.Classifier.conv6.weight', 'backbone.Classifier.conv6.bias', 'backbone.Classifier.bn6.weight', 'backbone.Classifier.bn6.bias', 'backbone.Classifier.bn6.running_mean', 'backbone.Classifier.bn6.running_var', 'backbone.Classifier.bn6.num_batches_tracked', 'backbone.Classifier.fc.weight', 'backbone.Classifier.fc.bias', 'backbone.Classifier.fc2.weight', 'backbone.Classifier.fc2.bias', 'backbone.Classifier.fc3.weight', 'backbone.Classifier.fc3.bias', 'backbone.Classifier.cls.0.weight', 'backbone.Classifier.cls.0.bias', 'proj.weight', 'proj.bias'])
cls token  tensor([[[ 0.0742, -0.6031, -0.0750,  ..., -1.3075,  0.4966, -0.7540]]],
       device='cuda:5')
rr  tensor([1.0738, 0.9827, 0.9756, 1.1247, 0.9363, 1.0295, 1.0171, 0.8772, 1.1414,
        0.8764, 1.0417, 1.0411, 0.9704, 0.8741, 1.0286, 0.8505, 1.1323, 1.0011,
        0.8609, 0.8905, 0.9876, 1.0116, 0.9802, 0.8808, 1.0316, 1.0559, 1.1463,
        1.0903, 0.9350, 1.0455, 0.9752, 0.8884, 0.8512, 1.0178, 1.0932, 1.1434,
        1.1080, 0.9231, 1.1499, 0.9333, 0.9124, 0.8827, 1.0343, 1.0172, 0.8646,
        1.1115, 0.8968, 1.1214, 1.1036, 1.0951, 0.9496, 1.1026, 1.0418, 0.9571,
        1.0756, 1.0673, 0.8579, 1.1263, 1.0073, 1.1280, 1.0781, 0.8988, 0.9347,
        1.0849, 1.0072, 0.9259, 1.0844, 0.8510, 0.8943, 0.8692, 1.0417, 1.1310,
        0.9874, 0.8866, 0.9528, 0.9757, 0.9415, 1.1430, 0.9416, 1.1242],
       device='cuda:5')
theta  tensor([1.3939, 2.4549, 1.6436, 1.5352, 0.7960, 3.0716, 2.6964, 2.0584, 0.7135,
        2.3078, 1.8680, 1.5814, 2.5930, 2.1385, 0.6050, 1.4292, 1.4744, 0.3818,
        2.0396, 2.8664, 0.4994, 2.8990, 1.4337, 2.9520, 2.1435, 1.2748, 0.3789,
        2.3218, 1.4669, 1.7877, 1.0691, 2.8505, 0.6513, 2.9708, 2.0885, 3.0277,
        1.2882, 1.7110, 2.6468, 2.2400, 1.1219, 0.2007, 0.5942, 0.7402, 2.4891,
        0.8861, 1.3891, 2.8232, 2.3094, 0.7382, 2.3175, 1.3819, 0.8533, 0.4777,
        3.0391, 1.8822, 1.2420, 3.1185, 0.1625, 0.9867, 1.3501, 2.3475, 1.5333,
        1.8721, 1.7133, 1.3431, 0.9326, 3.1381, 1.3014, 2.0869, 1.4987, 1.2876,
        2.5508, 0.4858, 1.6475, 0.5840, 1.7340, 1.2651, 3.0234, 2.8446],
       device='cuda:5')
cls  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:5')
pre_train: /home/balaji/crossView_CL/ModelFile/crossView_NUCLA/Multi/dy+bi+cl/dir-tenc-cl-mean/120.pth
loaded cls token  tensor([[[ 0.0678, -0.5492, -0.0683,  ..., -1.1908,  0.4520, -0.6864]]],
       device='cuda:5')
loaded rr  tensor([1.0599, 0.9743, 0.9663, 1.0703, 0.9268, 1.0206, 1.0072, 0.8694, 1.0412,
        0.8684, 1.0341, 1.0315, 0.9607, 0.8662, 0.9808, 0.8436, 1.0713, 0.9619,
        0.8533, 0.8830, 0.9458, 1.0024, 0.9725, 0.8735, 1.0197, 1.0501, 0.9950,
        1.0803, 0.9276, 1.0258, 0.9668, 0.8809, 0.8451, 1.0097, 1.0486, 1.0795,
        1.0817, 0.9156, 1.0775, 0.9241, 0.9034, 0.9111, 0.9747, 1.0095, 0.8571,
        1.0324, 0.8895, 1.0864, 1.0823, 1.0429, 0.9402, 1.0635, 0.9906, 0.9406,
        1.0659, 1.0572, 0.8507, 1.0796, 0.9868, 1.0320, 1.0559, 0.8908, 0.9269,
        1.0619, 0.9963, 0.9183, 1.0403, 0.8440, 0.8867, 0.8616, 1.0331, 1.0858,
        0.9757, 0.8722, 0.9442, 0.9596, 0.9335, 1.0722, 0.9340, 1.0885],
       device='cuda:5')
loaded theta  tensor([1.3831, 2.4351, 1.6302, 1.5173, 0.7894, 3.0460, 2.6738, 2.0410, 0.7377,
        2.2888, 1.8529, 1.5642, 2.5720, 2.1206, 0.6029, 1.4175, 1.4665, 0.3462,
        2.0224, 2.8426, 0.5185, 2.8750, 1.4217, 2.9278, 2.1216, 1.2670, 0.3556,
        2.2961, 1.4546, 1.7748, 1.0654, 2.8268, 0.6468, 2.9488, 2.0768, 3.0085,
        1.2792, 1.6970, 2.6287, 2.2216, 1.1125, 0.2004, 0.5884, 0.7404, 2.4684,
        0.9092, 1.3778, 2.8066, 2.2928, 0.7396, 2.2984, 1.3781, 0.8437, 0.4658,
        3.0172, 1.8672, 1.2320, 3.0912, 0.1108, 0.9424, 1.3398, 2.3283, 1.5204,
        1.8600, 1.6995, 1.3323, 0.9231, 3.1122, 1.2911, 2.0694, 1.4857, 1.2852,
        2.5297, 0.4884, 1.6341, 0.5822, 1.7197, 1.2677, 2.9984, 2.8182],
       device='cuda:5')
cls  tensor([0.8501, 0.8304, 0.8399, 0.8656, 0.7951, 0.8495, 0.8367, 0.8045, 0.8315,
        0.8346, 0.8355, 0.8365, 0.8201, 0.8282, 0.8473, 0.8448, 0.8442, 0.8319,
        0.8588, 0.8521, 0.8512, 0.8255, 0.8393, 0.8261, 0.8193, 0.8473, 0.8370,
        0.8597, 0.8751, 0.8255, 0.8253, 0.8407, 0.8280, 0.8370, 0.8604, 0.8473,
        0.8651, 0.8447, 0.8318, 0.8487, 0.8350, 0.8500, 0.8274, 0.8022, 0.8475,
        0.8413, 0.8316, 0.8393, 0.8229, 0.8409, 0.8307, 0.8596, 0.8457, 0.8425,
        0.8194, 0.8268, 0.8556, 0.8485, 0.8438, 0.8335, 0.8330, 0.8314, 0.8434,
        0.8416, 0.8375, 0.8239, 0.8493, 0.8421, 0.8607, 0.8365, 0.8267, 0.8485,
        0.8227, 0.8303, 0.8312, 0.8398, 0.8540, 0.8328, 0.8556, 0.8385, 0.8309,
        0.8417, 0.8307, 0.8517, 0.8200, 0.8409, 0.8578, 0.8444, 0.8580, 0.8369,
        0.8484, 0.8407, 0.8439, 0.8353, 0.8539, 0.8189, 0.8311, 0.8423, 0.8446,
        0.8441, 0.8261, 0.8253, 0.8221, 0.8547, 0.8060, 0.8552, 0.8289, 0.8427,
        0.8278, 0.8543, 0.8287, 0.8580, 0.8296, 0.8384, 0.8289, 0.8047, 0.8282,
        0.8393, 0.8169, 0.8399, 0.8317, 0.8332, 0.8359, 0.8187, 0.8432, 0.8413,
        0.8377, 0.8482, 0.8078, 0.8444, 0.8169, 0.8281, 0.8359, 0.8396, 0.8348,
        0.8171, 0.8313, 0.8224, 0.8377, 0.8497, 0.8353, 0.8440, 0.8315, 0.8469,
        0.8102, 0.8078, 0.8342, 0.8510, 0.8388, 0.8352, 0.8547, 0.8424, 0.8494,
        0.8638, 0.8326, 0.8254, 0.8351, 0.8287, 0.8268, 0.8180, 0.8465, 0.8523,
        0.8270, 0.8598, 0.8504, 0.8416, 0.8609, 0.8355, 0.8488, 0.8371, 0.8323,
        0.8245, 0.8379, 0.8567, 0.8400, 0.8372, 0.8174, 0.8401, 0.8387, 0.8265,
        0.8513, 0.8339, 0.8386, 0.8513, 0.8586, 0.8218, 0.8498, 0.8528, 0.8396,
        0.8472, 0.8293, 0.8510, 0.8413, 0.8074, 0.8183, 0.8274, 0.8327, 0.8312,
        0.8321, 0.8269, 0.8460, 0.8453, 0.8475, 0.8408, 0.8407, 0.8244, 0.8354,
        0.8692, 0.8126, 0.8381, 0.8449, 0.8511, 0.8666, 0.8418, 0.8452, 0.8232,
        0.8491, 0.8331, 0.8496, 0.8468, 0.8339, 0.8445, 0.8112, 0.8389, 0.8404,
        0.8571, 0.8222, 0.8481, 0.8239, 0.8462, 0.8429, 0.8447, 0.8126, 0.8151,
        0.8427, 0.8382, 0.8403, 0.8225, 0.8245, 0.8615, 0.8563, 0.8496, 0.8384,
        0.8114, 0.8336, 0.8185, 0.8292, 0.8423, 0.8759, 0.8117, 0.8445, 0.8326,
        0.8141, 0.8503, 0.8149, 0.8300], device='cuda:5')
plist  77
noplist  77
p  backbone.sparseCoding.rr False
p  backbone.sparseCoding.theta False
p  backbone.transformer_encoder.cls_token False
p  backbone.transformer_encoder.input_layer.weight False
p  backbone.transformer_encoder.input_layer.bias False
p  backbone.transformer_encoder.output_layer.weight False
p  backbone.transformer_encoder.output_layer.bias False
p  backbone.transformer_encoder.encoder_layer.self_attn.in_proj_weight False
p  backbone.transformer_encoder.encoder_layer.self_attn.in_proj_bias False
p  backbone.transformer_encoder.encoder_layer.self_attn.out_proj.weight False
p  backbone.transformer_encoder.encoder_layer.self_attn.out_proj.bias False
p  backbone.transformer_encoder.encoder_layer.linear1.weight False
p  backbone.transformer_encoder.encoder_layer.linear1.bias False
p  backbone.transformer_encoder.encoder_layer.linear2.weight False
p  backbone.transformer_encoder.encoder_layer.linear2.bias False
p  backbone.transformer_encoder.encoder_layer.norm1.weight False
p  backbone.transformer_encoder.encoder_layer.norm1.bias False
p  backbone.transformer_encoder.encoder_layer.norm2.weight False
p  backbone.transformer_encoder.encoder_layer.norm2.bias False
p  backbone.transformer_encoder.transformer_encoder.layers.0.self_attn.in_proj_weight False
p  backbone.transformer_encoder.transformer_encoder.layers.0.self_attn.in_proj_bias False
p  backbone.transformer_encoder.transformer_encoder.layers.0.self_attn.out_proj.weight False
p  backbone.transformer_encoder.transformer_encoder.layers.0.self_attn.out_proj.bias False
p  backbone.transformer_encoder.transformer_encoder.layers.0.linear1.weight False
p  backbone.transformer_encoder.transformer_encoder.layers.0.linear1.bias False
p  backbone.transformer_encoder.transformer_encoder.layers.0.linear2.weight False
p  backbone.transformer_encoder.transformer_encoder.layers.0.linear2.bias False
p  backbone.transformer_encoder.transformer_encoder.layers.0.norm1.weight False
p  backbone.transformer_encoder.transformer_encoder.layers.0.norm1.bias False
p  backbone.transformer_encoder.transformer_encoder.layers.0.norm2.weight False
p  backbone.transformer_encoder.transformer_encoder.layers.0.norm2.bias False
p  backbone.transformer_encoder.transformer_encoder.layers.1.self_attn.in_proj_weight False
p  backbone.transformer_encoder.transformer_encoder.layers.1.self_attn.in_proj_bias False
p  backbone.transformer_encoder.transformer_encoder.layers.1.self_attn.out_proj.weight False
p  backbone.transformer_encoder.transformer_encoder.layers.1.self_attn.out_proj.bias False
p  backbone.transformer_encoder.transformer_encoder.layers.1.linear1.weight False
p  backbone.transformer_encoder.transformer_encoder.layers.1.linear1.bias False
p  backbone.transformer_encoder.transformer_encoder.layers.1.linear2.weight False
p  backbone.transformer_encoder.transformer_encoder.layers.1.linear2.bias False
p  backbone.transformer_encoder.transformer_encoder.layers.1.norm1.weight False
p  backbone.transformer_encoder.transformer_encoder.layers.1.norm1.bias False
p  backbone.transformer_encoder.transformer_encoder.layers.1.norm2.weight False
p  backbone.transformer_encoder.transformer_encoder.layers.1.norm2.bias False
p  backbone.Classifier.conv1.weight True
p  backbone.Classifier.conv1.bias True
p  backbone.Classifier.bn1.weight True
p  backbone.Classifier.bn1.bias True
p  backbone.Classifier.conv2.weight True
p  backbone.Classifier.conv2.bias True
p  backbone.Classifier.bn2.weight True
p  backbone.Classifier.bn2.bias True
p  backbone.Classifier.conv3.weight True
p  backbone.Classifier.conv3.bias True
p  backbone.Classifier.bn3.weight True
p  backbone.Classifier.bn3.bias True
p  backbone.Classifier.conv4.weight True
p  backbone.Classifier.conv4.bias True
p  backbone.Classifier.bn4.weight True
p  backbone.Classifier.bn4.bias True
p  backbone.Classifier.conv5.weight True
p  backbone.Classifier.conv5.bias True
p  backbone.Classifier.bn5.weight True
p  backbone.Classifier.bn5.bias True
p  backbone.Classifier.conv6.weight True
p  backbone.Classifier.conv6.bias True
p  backbone.Classifier.bn6.weight True
p  backbone.Classifier.bn6.bias True
p  backbone.Classifier.fc.weight True
p  backbone.Classifier.fc.bias True
p  backbone.Classifier.fc2.weight True
p  backbone.Classifier.fc2.bias True
p  backbone.Classifier.fc3.weight True
p  backbone.Classifier.fc3.bias True
p  backbone.Classifier.cls.0.weight True
p  backbone.Classifier.cls.0.bias True
p  proj.weight False
p  proj.bias False
cls token  tensor([[[ 0.0678, -0.5492, -0.0683,  ..., -1.1908,  0.4520, -0.6864]]],
       device='cuda:5')
after rr  tensor([1.0599, 0.9743, 0.9663, 1.0703, 0.9268, 1.0206, 1.0072, 0.8694, 1.0412,
        0.8684, 1.0341, 1.0315, 0.9607, 0.8662, 0.9808, 0.8436, 1.0713, 0.9619,
        0.8533, 0.8830, 0.9458, 1.0024, 0.9725, 0.8735, 1.0197, 1.0501, 0.9950,
        1.0803, 0.9276, 1.0258, 0.9668, 0.8809, 0.8451, 1.0097, 1.0486, 1.0795,
        1.0817, 0.9156, 1.0775, 0.9241, 0.9034, 0.9111, 0.9747, 1.0095, 0.8571,
        1.0324, 0.8895, 1.0864, 1.0823, 1.0429, 0.9402, 1.0635, 0.9906, 0.9406,
        1.0659, 1.0572, 0.8507, 1.0796, 0.9868, 1.0320, 1.0559, 0.8908, 0.9269,
        1.0619, 0.9963, 0.9183, 1.0403, 0.8440, 0.8867, 0.8616, 1.0331, 1.0858,
        0.9757, 0.8722, 0.9442, 0.9596, 0.9335, 1.0722, 0.9340, 1.0885],
       device='cuda:5')
after theta  tensor([1.3831, 2.4351, 1.6302, 1.5173, 0.7894, 3.0460, 2.6738, 2.0410, 0.7377,
        2.2888, 1.8529, 1.5642, 2.5720, 2.1206, 0.6029, 1.4175, 1.4665, 0.3462,
        2.0224, 2.8426, 0.5185, 2.8750, 1.4217, 2.9278, 2.1216, 1.2670, 0.3556,
        2.2961, 1.4546, 1.7748, 1.0654, 2.8268, 0.6468, 2.9488, 2.0768, 3.0085,
        1.2792, 1.6970, 2.6287, 2.2216, 1.1125, 0.2004, 0.5884, 0.7404, 2.4684,
        0.9092, 1.3778, 2.8066, 2.2928, 0.7396, 2.2984, 1.3781, 0.8437, 0.4658,
        3.0172, 1.8672, 1.2320, 3.0912, 0.1108, 0.9424, 1.3398, 2.3283, 1.5204,
        1.8600, 1.6995, 1.3323, 0.9231, 3.1122, 1.2911, 2.0694, 1.4857, 1.2852,
        2.5297, 0.4884, 1.6341, 0.5822, 1.7197, 1.2677, 2.9984, 2.8182],
       device='cuda:5')
cls  tensor([0.8501, 0.8304, 0.8399, 0.8656, 0.7951, 0.8495, 0.8367, 0.8045, 0.8315,
        0.8346, 0.8355, 0.8365, 0.8201, 0.8282, 0.8473, 0.8448, 0.8442, 0.8319,
        0.8588, 0.8521, 0.8512, 0.8255, 0.8393, 0.8261, 0.8193, 0.8473, 0.8370,
        0.8597, 0.8751, 0.8255, 0.8253, 0.8407, 0.8280, 0.8370, 0.8604, 0.8473,
        0.8651, 0.8447, 0.8318, 0.8487, 0.8350, 0.8500, 0.8274, 0.8022, 0.8475,
        0.8413, 0.8316, 0.8393, 0.8229, 0.8409, 0.8307, 0.8596, 0.8457, 0.8425,
        0.8194, 0.8268, 0.8556, 0.8485, 0.8438, 0.8335, 0.8330, 0.8314, 0.8434,
        0.8416, 0.8375, 0.8239, 0.8493, 0.8421, 0.8607, 0.8365, 0.8267, 0.8485,
        0.8227, 0.8303, 0.8312, 0.8398, 0.8540, 0.8328, 0.8556, 0.8385, 0.8309,
        0.8417, 0.8307, 0.8517, 0.8200, 0.8409, 0.8578, 0.8444, 0.8580, 0.8369,
        0.8484, 0.8407, 0.8439, 0.8353, 0.8539, 0.8189, 0.8311, 0.8423, 0.8446,
        0.8441, 0.8261, 0.8253, 0.8221, 0.8547, 0.8060, 0.8552, 0.8289, 0.8427,
        0.8278, 0.8543, 0.8287, 0.8580, 0.8296, 0.8384, 0.8289, 0.8047, 0.8282,
        0.8393, 0.8169, 0.8399, 0.8317, 0.8332, 0.8359, 0.8187, 0.8432, 0.8413,
        0.8377, 0.8482, 0.8078, 0.8444, 0.8169, 0.8281, 0.8359, 0.8396, 0.8348,
        0.8171, 0.8313, 0.8224, 0.8377, 0.8497, 0.8353, 0.8440, 0.8315, 0.8469,
        0.8102, 0.8078, 0.8342, 0.8510, 0.8388, 0.8352, 0.8547, 0.8424, 0.8494,
        0.8638, 0.8326, 0.8254, 0.8351, 0.8287, 0.8268, 0.8180, 0.8465, 0.8523,
        0.8270, 0.8598, 0.8504, 0.8416, 0.8609, 0.8355, 0.8488, 0.8371, 0.8323,
        0.8245, 0.8379, 0.8567, 0.8400, 0.8372, 0.8174, 0.8401, 0.8387, 0.8265,
        0.8513, 0.8339, 0.8386, 0.8513, 0.8586, 0.8218, 0.8498, 0.8528, 0.8396,
        0.8472, 0.8293, 0.8510, 0.8413, 0.8074, 0.8183, 0.8274, 0.8327, 0.8312,
        0.8321, 0.8269, 0.8460, 0.8453, 0.8475, 0.8408, 0.8407, 0.8244, 0.8354,
        0.8692, 0.8126, 0.8381, 0.8449, 0.8511, 0.8666, 0.8418, 0.8452, 0.8232,
        0.8491, 0.8331, 0.8496, 0.8468, 0.8339, 0.8445, 0.8112, 0.8389, 0.8404,
        0.8571, 0.8222, 0.8481, 0.8239, 0.8462, 0.8429, 0.8447, 0.8126, 0.8151,
        0.8427, 0.8382, 0.8403, 0.8225, 0.8245, 0.8615, 0.8563, 0.8496, 0.8384,
        0.8114, 0.8336, 0.8185, 0.8292, 0.8423, 0.8759, 0.8117, 0.8445, 0.8326,
        0.8141, 0.8503, 0.8149, 0.8300], device='cuda:5')
optimizer  SGD (
Parameter Group 0
    dampening: 0
    lr: 0.001
    momentum: 0.9
    nesterov: False
    weight_decay: 0.001
)
start training epoch: 0
epoch: 0 |loss: 3.6902109221555293 |cls: 1.8401291142217815 |mse: 0.00841281969769625 |bi: 0.015398775747598847
training time(min): 9.949364372094472
sample: 0
sample: 1
sample: 2
sample: 3
sample: 4
sample: 5
sample: 6
sample: 7
sample: 8
sample: 9
sample: 10
sample: 11
sample: 12
sample: 13
sample: 14
sample: 15
sample: 16
sample: 17
sample: 18
sample: 19
sample: 20
sample: 21
sample: 22
sample: 23
sample: 24
sample: 25
sample: 26
sample: 27
sample: 28
sample: 29
sample: 30
sample: 31
sample: 32
sample: 33
sample: 34
sample: 35
sample: 36
sample: 37
sample: 38
sample: 39
sample: 40
sample: 41
sample: 42
sample: 43
sample: 44
sample: 45
sample: 46
sample: 47
sample: 48
sample: 49
sample: 50
sample: 51
sample: 52
sample: 53
sample: 54
sample: 55
sample: 56
sample: 57
testing epoch: 0 Acc:0.2414
start training epoch: 1
epoch: 1 |loss: 3.317630162462592 |cls: 1.6538417753763497 |mse: 0.008405254935496487 |bi: 0.01541352273125085
training time(min): 9.915957260131837
start training epoch: 2
epoch: 2 |loss: 3.140282209031284 |cls: 1.5651487952563912 |mse: 0.008442441730949213 |bi: 0.015421658223203849
training time(min): 10.256014064947765
start training epoch: 3
epoch: 3 |loss: 3.015431038569659 |cls: 1.5027347547002137 |mse: 0.008419482168392278 |bi: 0.015420543721120339
training time(min): 10.487544385592143
start training epoch: 4
epoch: 4 |loss: 2.9226419706828892 |cls: 1.456334418617189 |mse: 0.008430798105109716 |bi: 0.015423341443238314
training time(min): 9.965026279290518
start training epoch: 5
epoch: 5 |loss: 2.8344905893318355 |cls: 1.4122690008953214 |mse: 0.00841193831183773 |bi: 0.0154064487433061
training time(min): 10.134532570838928
start training epoch: 6
epoch: 6 |loss: 2.7349071260541677 |cls: 1.3624774129129946 |mse: 0.008410673684920766 |bi: 0.015416214318975108
training time(min): 10.135246896743775
start training epoch: 7
epoch: 7 |loss: 2.6475735087879 |cls: 1.3187983843963593 |mse: 0.008434230594502878 |bi: 0.015424979133968009
training time(min): 10.181929222742717
start training epoch: 8
epoch: 8 |loss: 2.5140464594587684 |cls: 1.2520385747775435 |mse: 0.00842675822059391 |bi: 0.015425517445692094
training time(min): 9.706741364796956
start training epoch: 9
epoch: 9 |loss: 2.517851926619187 |cls: 1.253941418020986 |mse: 0.008428035258475575 |bi: 0.015410543026519008
training time(min): 9.986470707257588
start training epoch: 10
epoch: 10 |loss: 2.4686083612032235 |cls: 1.2293100857641548 |mse: 0.008443757333225221 |bi: 0.015444442131411051
training time(min): 9.901859331130982
sample: 0
sample: 1
sample: 2
sample: 3
sample: 4
sample: 5
sample: 6
sample: 7
sample: 8
sample: 9
sample: 10
sample: 11
sample: 12
sample: 13
sample: 14
sample: 15
sample: 16
sample: 17
sample: 18
sample: 19
sample: 20
sample: 21
sample: 22
sample: 23
sample: 24
sample: 25
sample: 26
sample: 27
sample: 28
sample: 29
sample: 30
sample: 31
sample: 32
sample: 33
sample: 34
sample: 35
sample: 36
sample: 37
sample: 38
sample: 39
sample: 40
sample: 41
sample: 42
sample: 43
sample: 44
sample: 45
sample: 46
sample: 47
sample: 48
sample: 49
sample: 50
sample: 51
sample: 52
sample: 53
sample: 54
sample: 55
sample: 56
sample: 57
testing epoch: 10 Acc:0.3836
start training epoch: 11
epoch: 11 |loss: 2.385942585300654 |cls: 1.18799103226047 |mse: 0.00842047483092756 |bi: 0.01540045891306363
training time(min): 10.023339347044628
start training epoch: 12
epoch: 12 |loss: 2.3433757978491485 |cls: 1.1667085455264896 |mse: 0.008416247328568716 |bi: 0.015424607641762123
training time(min): 9.890109940369923
start training epoch: 13
epoch: 13 |loss: 2.2313785469159484 |cls: 1.1107151779578999 |mse: 0.008407577812249656 |bi: 0.015406130263727391
training time(min): 10.217756938934325
start training epoch: 14
epoch: 14 |loss: 2.2207942560780793 |cls: 1.1054206708213314 |mse: 0.008410559734329581 |bi: 0.015423500659380807
training time(min): 9.775876418749492
start training epoch: 15
epoch: 15 |loss: 2.1037297006696463 |cls: 1.0468645989894867 |mse: 0.008458097247057594 |bi: 0.015424076893395977
training time(min): 9.87973616917928
start training epoch: 16
epoch: 16 |loss: 2.155316417571157 |cls: 1.0726676123449579 |mse: 0.008438759005002794 |bi: 0.015424418059410527
training time(min): 10.296247907479604
start training epoch: 17
epoch: 17 |loss: 2.050052351434715 |cls: 1.0200588856823742 |mse: 0.008394893059630704 |bi: 0.01539681952635874
training time(min): 11.324375621477763
start training epoch: 18
epoch: 18 |loss: 1.9769759990740567 |cls: 0.9835077267489396 |mse: 0.008419934869380086 |bi: 0.01540612270400743
training time(min): 11.404639931519826
start training epoch: 19
epoch: 19 |loss: 1.9239626105409116 |cls: 0.9569971814053133 |mse: 0.008425048838034854 |bi: 0.015431954634550493
training time(min): 11.654483954111734
start training epoch: 20
epoch: 20 |loss: 1.8779371555428952 |cls: 0.9339896314777434 |mse: 0.008417767863647896 |bi: 0.01540117921831552
training time(min): 11.465908825397491
sample: 0
sample: 1
sample: 2
sample: 3
sample: 4
sample: 5
sample: 6
sample: 7
sample: 8
sample: 9
sample: 10
sample: 11
sample: 12
sample: 13
sample: 14
sample: 15
sample: 16
sample: 17
sample: 18
sample: 19
sample: 20
sample: 21
sample: 22
sample: 23
sample: 24
sample: 25
sample: 26
sample: 27
sample: 28
sample: 29
sample: 30
sample: 31
sample: 32
sample: 33
sample: 34
sample: 35
sample: 36
sample: 37
sample: 38
sample: 39
sample: 40
sample: 41
sample: 42
sample: 43
sample: 44
sample: 45
sample: 46
sample: 47
sample: 48
sample: 49
sample: 50
sample: 51
sample: 52
sample: 53
sample: 54
sample: 55
sample: 56
sample: 57
testing epoch: 20 Acc:0.4353
start training epoch: 21
epoch: 21 |loss: 1.9006935814977624 |cls: 0.9453475379559677 |mse: 0.008454192669887561 |bi: 0.015442994015756994
training time(min): 11.089652641614277
start training epoch: 22
epoch: 22 |loss: 1.8148489627055824 |cls: 0.9024530648021027 |mse: 0.008402093128097476 |bi: 0.015407434333610581
training time(min): 11.153763794898987
start training epoch: 23
epoch: 23 |loss: 1.7562775049591437 |cls: 0.8731656793970615 |mse: 0.008404247246289742 |bi: 0.015419042440043995
training time(min): 10.942824451128642
start training epoch: 24
epoch: 24 |loss: 1.7092555090785027 |cls: 0.8496449493104592 |mse: 0.008423917724940111 |bi: 0.015416957401612308
training time(min): 11.645303869247437
start training epoch: 25
epoch: 25 |loss: 1.7352929471526295 |cls: 0.8626548806205392 |mse: 0.008438906068477081 |bi: 0.01544278168148594
training time(min): 11.411714800198872
start training epoch: 26
epoch: 26 |loss: 1.6785791381262243 |cls: 0.8343082140781917 |mse: 0.008420239097176818 |bi: 0.015424691016960423
training time(min): 11.255155177911123
start training epoch: 27
epoch: 27 |loss: 1.6233259020373225 |cls: 0.8066841225954704 |mse: 0.00841638876045181 |bi: 0.015412673576065572
training time(min): 11.47360801299413
start training epoch: 28
epoch: 28 |loss: 1.6357742032269016 |cls: 0.8129136365023442 |mse: 0.00840784048432397 |bi: 0.015390852513519349
training time(min): 11.149823705355326
start training epoch: 29
epoch: 29 |loss: 1.636488740798086 |cls: 0.8132625469006598 |mse: 0.008420656087764655 |bi: 0.015429907449288294
training time(min): 11.270126005013784
start training epoch: 30
epoch: 30 |loss: 1.53107952082064 |cls: 0.760541918920353 |mse: 0.008451803138086689 |bi: 0.015438846665347228
training time(min): 11.434778086344402
sample: 0
sample: 1
sample: 2
sample: 3
sample: 4
sample: 5
sample: 6
sample: 7
sample: 8
sample: 9
sample: 10
sample: 11
sample: 12
sample: 13
sample: 14
sample: 15
sample: 16
sample: 17
sample: 18
sample: 19
sample: 20
sample: 21
sample: 22
sample: 23
sample: 24
sample: 25
sample: 26
sample: 27
sample: 28
sample: 29
sample: 30
sample: 31
sample: 32
sample: 33
sample: 34
sample: 35
sample: 36
sample: 37
sample: 38
sample: 39
sample: 40
sample: 41
sample: 42
sample: 43
sample: 44
sample: 45
sample: 46
sample: 47
sample: 48
sample: 49
sample: 50
sample: 51
sample: 52
sample: 53
sample: 54
sample: 55
sample: 56
sample: 57
testing epoch: 30 Acc:0.3750
start training epoch: 31
epoch: 31 |loss: 1.4947636583819985 |cls: 0.7423879092093557 |mse: 0.008443570612143958 |bi: 0.015442645199073013
training time(min): 11.572229874134063
start training epoch: 32
epoch: 32 |loss: 1.4746094185393304 |cls: 0.7323363143368624 |mse: 0.008396582845307421 |bi: 0.015402073884615675
training time(min): 11.835348860422771
start training epoch: 33
epoch: 33 |loss: 1.4849909660988487 |cls: 0.7375074229785241 |mse: 0.008433497092482867 |bi: 0.015426245332491817
training time(min): 11.395501784483592
start training epoch: 34
epoch: 34 |loss: 1.4462148405145854 |cls: 0.7181198782636784 |mse: 0.008432555900071748 |bi: 0.01542526729463134
training time(min): 12.994515152772268
start training epoch: 35
epoch: 35 |loss: 1.3766204899875447 |cls: 0.6833227871975396 |mse: 0.008432823153270874 |bi: 0.015420922754856292
training time(min): 13.839688563346863
start training epoch: 36
epoch: 36 |loss: 1.4501581290969625 |cls: 0.720083713036729 |mse: 0.008446412317425711 |bi: 0.015442857478774386
training time(min): 12.448776149749756
start training epoch: 37
epoch: 37 |loss: 1.4304332805913873 |cls: 0.7102278744569048 |mse: 0.008433793134827283 |bi: 0.015437398411449976
training time(min): 14.133255370457967
start training epoch: 38
epoch: 38 |loss: 1.232430563599337 |cls: 0.6112404754967429 |mse: 0.00840836339739326 |bi: 0.015412521926918998
training time(min): 13.905545071760814
start training epoch: 39
epoch: 39 |loss: 1.2989667899091728 |cls: 0.644496433873428 |mse: 0.008430800846326747 |bi: 0.015431203988555353
training time(min): 13.710320138931275
start training epoch: 40
epoch: 40 |loss: 1.3375527401803993 |cls: 0.6637955933401827 |mse: 0.008420000855039689 |bi: 0.015415600155392895
training time(min): 13.58853457768758
sample: 0
sample: 1
sample: 2
sample: 3
sample: 4
sample: 5
sample: 6
sample: 7
sample: 8
sample: 9
sample: 10
sample: 11
sample: 12
sample: 13
sample: 14
sample: 15
sample: 16
sample: 17
sample: 18
sample: 19
sample: 20
sample: 21
sample: 22
sample: 23
sample: 24
sample: 25
sample: 26
sample: 27
sample: 28
sample: 29
sample: 30
sample: 31
sample: 32
sample: 33
sample: 34
sample: 35
sample: 36
sample: 37
sample: 38
sample: 39
sample: 40
sample: 41
sample: 42
sample: 43
sample: 44
sample: 45
sample: 46
sample: 47
sample: 48
sample: 49
sample: 50
sample: 51
sample: 52
sample: 53
sample: 54
sample: 55
sample: 56
sample: 57
testing epoch: 40 Acc:0.3772
start training epoch: 41
epoch: 41 |loss: 1.2507446304080077 |cls: 0.6203993479721248 |mse: 0.00840578672978154 |bi: 0.015401512806420214
training time(min): 13.616741927464803
start training epoch: 42
epoch: 42 |loss: 1.2230342057300732 |cls: 0.6065484906430356 |mse: 0.008397129173317808 |bi: 0.015400959360704292
training time(min): 13.768690387407938
start training epoch: 43
epoch: 43 |loss: 1.1720192338107154 |cls: 0.5810238065314479 |mse: 0.00842903553711949 |bi: 0.015425858662638348
training time(min): 13.302517759799958
start training epoch: 44
epoch: 44 |loss: 1.1592357133631594 |cls: 0.5746362815989414 |mse: 0.00842262332480459 |bi: 0.015405326601467095
training time(min): 13.325059262911479
start training epoch: 45
epoch: 45 |loss: 1.2020811812835746 |cls: 0.596033651381731 |mse: 0.008467324749290128 |bi: 0.01546552015497582
training time(min): 13.609542957941692
start training epoch: 46
epoch: 46 |loss: 1.1848929090774618 |cls: 0.5874612498737406 |mse: 0.008429006460573873 |bi: 0.015414038334711222
training time(min): 13.652640914916992
start training epoch: 47
epoch: 47 |loss: 1.232470502029173 |cls: 0.6112648935086327 |mse: 0.008399417905820883 |bi: 0.015412946548167383
training time(min): 13.735683866341908
start training epoch: 48
epoch: 48 |loss: 1.131045133137377 |cls: 0.5605483046601876 |mse: 0.008406831466345466 |bi: 0.015416927042679163
training time(min): 13.384611717859904
start training epoch: 49
epoch: 49 |loss: 1.1151415613712743 |cls: 0.5525848059041891 |mse: 0.00842994263075525 |bi: 0.015420073556015268
training time(min): 13.09641455411911
start training epoch: 50
epoch: 50 |loss: 0.7602617455704603 |cls: 0.3751470001152484 |mse: 0.008424450279562734 |bi: 0.015432955417054472
training time(min): 14.069365227222443
sample: 0
sample: 1
sample: 2
sample: 3
sample: 4
sample: 5
sample: 6
sample: 7
sample: 8
sample: 9
sample: 10
sample: 11
sample: 12
sample: 13
sample: 14
sample: 15
sample: 16
sample: 17
sample: 18
sample: 19
sample: 20
sample: 21
sample: 22
sample: 23
sample: 24
sample: 25
sample: 26
sample: 27
sample: 28
sample: 29
sample: 30
sample: 31
sample: 32
sample: 33
sample: 34
sample: 35
sample: 36
sample: 37
sample: 38
sample: 39
sample: 40
sample: 41
sample: 42
sample: 43
sample: 44
sample: 45
sample: 46
sample: 47
sample: 48
sample: 49
sample: 50
sample: 51
sample: 52
sample: 53
sample: 54
sample: 55
sample: 56
sample: 57
testing epoch: 50 Acc:0.4246
start training epoch: 51
epoch: 51 |loss: 0.7037674799066735 |cls: 0.34689820697167306 |mse: 0.00842835936055053 |bi: 0.015427079357323237
training time(min): 14.456258185704549
start training epoch: 52
epoch: 52 |loss: 0.6126240766607225 |cls: 0.30133843889052514 |mse: 0.008406206925428705 |bi: 0.015409943993290653
training time(min): 13.926767035325367
start training epoch: 53
epoch: 53 |loss: 0.651200646549114 |cls: 0.32062136020249454 |mse: 0.008416017479248694 |bi: 0.015419049999763956
training time(min): 14.000058245658874
start training epoch: 54
epoch: 54 |loss: 0.5870432526280638 |cls: 0.2885475117363967 |mse: 0.008407838839048054 |bi: 0.015403885987325339
training time(min): 14.216693778832754
start training epoch: 55
epoch: 55 |loss: 0.5632971019513207 |cls: 0.27664214225660544 |mse: 0.008468082365652663 |bi: 0.015447353645868134
training time(min): 13.747336300214132
start training epoch: 56
epoch: 56 |loss: 0.5772454251273302 |cls: 0.28364637609774945 |mse: 0.008412035032961285 |bi: 0.015406403250381118
training time(min): 13.808467733860017
start training epoch: 57
epoch: 57 |loss: 0.5485262104630237 |cls: 0.2692962762484967 |mse: 0.008393805945161148 |bi: 0.01539851035704487
training time(min): 13.79275027513504
start training epoch: 58
epoch: 58 |loss: 0.569642459449824 |cls: 0.2798510434113268 |mse: 0.008400657230595243 |bi: 0.015397153179947054
training time(min): 13.987990387280782
start training epoch: 59
epoch: 59 |loss: 0.5477795006445376 |cls: 0.2689005906577222 |mse: 0.008435497768005007 |bi: 0.015428224309289362
training time(min): 13.593584458033243
start training epoch: 60
epoch: 60 |loss: 0.5289581109173014 |cls: 0.2594945824966999 |mse: 0.00842796820870717 |bi: 0.015409777202876285
training time(min): 12.484559468428294
sample: 0
sample: 1
sample: 2
sample: 3
sample: 4
sample: 5
sample: 6
sample: 7
sample: 8
sample: 9
sample: 10
sample: 11
sample: 12
sample: 13
sample: 14
sample: 15
sample: 16
sample: 17
sample: 18
sample: 19
sample: 20
sample: 21
sample: 22
sample: 23
sample: 24
sample: 25
sample: 26
sample: 27
sample: 28
sample: 29
sample: 30
sample: 31
sample: 32
sample: 33
sample: 34
sample: 35
sample: 36
sample: 37
sample: 38
sample: 39
sample: 40
sample: 41
sample: 42
sample: 43
sample: 44
sample: 45
sample: 46
sample: 47
sample: 48
sample: 49
sample: 50
sample: 51
sample: 52
sample: 53
sample: 54
sample: 55
sample: 56
sample: 57
testing epoch: 60 Acc:0.4526
start training epoch: 61
epoch: 61 |loss: 0.5797708161553601 |cls: 0.2849172791065939 |mse: 0.008395644164920668 |bi: 0.015406130281917285
training time(min): 11.910138193766276
start training epoch: 62
epoch: 62 |loss: 0.4964065503590973 |cls: 0.24322468506579753 |mse: 0.008415258142122184 |bi: 0.015419239582115551
training time(min): 11.31786855061849
start training epoch: 63
epoch: 63 |loss: 0.4915255777013954 |cls: 0.24077954189124284 |mse: 0.008424616140473518 |bi: 0.015418784660141682
training time(min): 11.359485272566477
start training epoch: 64
epoch: 64 |loss: 0.4772249494344578 |cls: 0.23362981640093494 |mse: 0.008424369676504284 |bi: 0.01540945873784949
training time(min): 11.282122381528218
start training epoch: 65
epoch: 65 |loss: 0.47704082009295234 |cls: 0.23354111668959376 |mse: 0.008417817733061383 |bi: 0.015407692153530661
training time(min): 11.19446869691213
start training epoch: 66
epoch: 66 |loss: 0.5028815073965234 |cls: 0.24644922570951167 |mse: 0.008440939065621933 |bi: 0.015421180552948499
training time(min): 11.22982479731242
start training epoch: 67
epoch: 67 |loss: 0.5047427714671358 |cls: 0.2473780045129388 |mse: 0.008443330340014654 |bi: 0.01543432015387225
training time(min): 11.136091848214468
start training epoch: 68
epoch: 68 |loss: 0.4855279633484315 |cls: 0.23778906750521855 |mse: 0.008408967887589824 |bi: 0.015408602001116378
training time(min): 11.187423904736837
start training epoch: 69
epoch: 69 |loss: 0.473267983259575 |cls: 0.23165065525608952 |mse: 0.008424540490523214 |bi: 0.01542132464601309
training time(min): 11.239106810092926
start training epoch: 70
epoch: 70 |loss: 0.47715166892885463 |cls: 0.23358899246522924 |mse: 0.008431408830801956 |bi: 0.015422734912135638
training time(min): 11.36626337369283
sample: 0
sample: 1
sample: 2
sample: 3
sample: 4
sample: 5
sample: 6
sample: 7
sample: 8
sample: 9
sample: 10
sample: 11
sample: 12
sample: 13
sample: 14
sample: 15
sample: 16
sample: 17
sample: 18
sample: 19
sample: 20
sample: 21
sample: 22
sample: 23
sample: 24
sample: 25
sample: 26
sample: 27
sample: 28
sample: 29
sample: 30
sample: 31
sample: 32
sample: 33
sample: 34
sample: 35
sample: 36
sample: 37
sample: 38
sample: 39
sample: 40
sample: 41
sample: 42
sample: 43
sample: 44
sample: 45
sample: 46
sample: 47
sample: 48
sample: 49
sample: 50
sample: 51
sample: 52
sample: 53
sample: 54
sample: 55
sample: 56
sample: 57
testing epoch: 70 Acc:0.4828
start training epoch: 71
epoch: 71 |loss: 0.4549372819092241 |cls: 0.2224767307379807 |mse: 0.008440887620963622 |bi: 0.015429323586431565
training time(min): 11.451936729749043
start training epoch: 72
epoch: 72 |loss: 0.4440884939467651 |cls: 0.21707726889508194 |mse: 0.00839414237634628 |bi: 0.015398123679915443
training time(min): 11.00815912882487
start training epoch: 73
epoch: 73 |loss: 0.4340155195022817 |cls: 0.2120177666311065 |mse: 0.008438005610514665 |bi: 0.015419785519043216
training time(min): 11.10792144536972
start training epoch: 74
epoch: 74 |loss: 0.4764536568109179 |cls: 0.23325599773670547 |mse: 0.008401441242313012 |bi: 0.015402217959490372
training time(min): 11.253414436181385
start training epoch: 75
epoch: 75 |loss: 0.4666052227548789 |cls: 0.2283292376305326 |mse: 0.008405243855122535 |bi: 0.015415039128129138
training time(min): 11.185058796405793
start training epoch: 76
epoch: 76 |loss: 0.454808496098849 |cls: 0.2224231416475959 |mse: 0.008420862392085837 |bi: 0.01541349998296937
training time(min): 11.296103092034658
start training epoch: 77
epoch: 77 |loss: 0.4509015854491736 |cls: 0.22047407666650543 |mse: 0.00841241122543579 |bi: 0.015410232143040048
training time(min): 11.00847160021464
start training epoch: 78
epoch: 78 |loss: 0.4335039685538504 |cls: 0.21177571305815945 |mse: 0.008411292414166383 |bi: 0.01541248401554185
training time(min): 10.26885664065679
start training epoch: 79
epoch: 79 |loss: 0.4557777660083957 |cls: 0.22291325730839162 |mse: 0.008410106054725475 |bi: 0.015411437696457142
training time(min): 9.731539686520895
start training epoch: 80
epoch: 80 |loss: 0.42227872630610364 |cls: 0.20612369026093802 |mse: 0.008487191060339683 |bi: 0.015441538253071485
training time(min): 9.717198876539866
sample: 0
sample: 1
sample: 2
sample: 3
sample: 4
sample: 5
sample: 6
sample: 7
sample: 8
sample: 9
sample: 10
sample: 11
sample: 12
sample: 13
sample: 14
sample: 15
sample: 16
sample: 17
sample: 18
sample: 19
sample: 20
sample: 21
sample: 22
sample: 23
sample: 24
sample: 25
sample: 26
sample: 27
sample: 28
sample: 29
sample: 30
sample: 31
sample: 32
sample: 33
sample: 34
sample: 35
sample: 36
sample: 37
sample: 38
sample: 39
sample: 40
sample: 41
sample: 42
sample: 43
sample: 44
sample: 45
sample: 46
sample: 47
sample: 48
sample: 49
sample: 50
sample: 51
sample: 52
sample: 53
sample: 54
sample: 55
sample: 56
sample: 57
testing epoch: 80 Acc:0.4784
start training epoch: 81
epoch: 81 |loss: 0.4367565828797524 |cls: 0.21340852934645227 |mse: 0.008397505303946673 |bi: 0.015420179744978668
training time(min): 9.594178581237793
start training epoch: 82
epoch: 82 |loss: 0.42383313398750033 |cls: 0.20692926773517684 |mse: 0.008431380168985925 |bi: 0.015432174470333848
training time(min): 9.484621810913087
start training epoch: 83
epoch: 83 |loss: 0.42286823890026426 |cls: 0.20645889599654765 |mse: 0.008409124666286516 |bi: 0.015413219418405788
training time(min): 9.543686147530874
start training epoch: 84
epoch: 84 |loss: 0.45761543997650733 |cls: 0.22382930492676678 |mse: 0.008416150874836603 |bi: 0.015406789956614375
training time(min): 9.49617109298706
start training epoch: 85
epoch: 85 |loss: 0.44058859342476353 |cls: 0.21531095112732146 |mse: 0.008423142033279873 |bi: 0.015435495388373965
training time(min): 9.630717730522155
start training epoch: 86
epoch: 86 |loss: 0.42726049236080144 |cls: 0.20864703458755685 |mse: 0.008424394582107197 |bi: 0.015420293446368305
training time(min): 9.796182767550151
start training epoch: 87
epoch: 87 |loss: 0.39265213487669826 |cls: 0.19135032573103672 |mse: 0.008410897362409742 |bi: 0.015405857313453453
training time(min): 9.926819411913554
start training epoch: 88
epoch: 88 |loss: 0.44890677990042605 |cls: 0.2194705133624666 |mse: 0.00842384389761719 |bi: 0.015419118230056483
training time(min): 9.6535466949145
start training epoch: 89
epoch: 89 |loss: 0.49258083284803433 |cls: 0.24132026390361716 |mse: 0.008399500984523911 |bi: 0.01540804856995237
training time(min): 9.707342839241027
start training epoch: 90
epoch: 90 |loss: 0.4462706579215592 |cls: 0.2181385775347735 |mse: 0.00845022114845051 |bi: 0.015432803778821835
training time(min): 9.795949951807659
sample: 0
sample: 1
sample: 2
sample: 3
sample: 4
sample: 5
sample: 6
sample: 7
sample: 8
sample: 9
sample: 10
sample: 11
sample: 12
sample: 13
sample: 14
sample: 15
sample: 16
sample: 17
sample: 18
sample: 19
sample: 20
sample: 21
sample: 22
sample: 23
sample: 24
sample: 25
sample: 26
sample: 27
sample: 28
sample: 29
sample: 30
sample: 31
sample: 32
sample: 33
sample: 34
sample: 35
sample: 36
sample: 37
sample: 38
sample: 39
sample: 40
sample: 41
sample: 42
sample: 43
sample: 44
sample: 45
sample: 46
sample: 47
sample: 48
sample: 49
sample: 50
sample: 51
sample: 52
sample: 53
sample: 54
sample: 55
sample: 56
sample: 57
testing epoch: 90 Acc:0.4483
start training epoch: 91
epoch: 91 |loss: 0.4585184164243401 |cls: 0.22428773939464008 |mse: 0.008402430622481916 |bi: 0.01540507642130251
training time(min): 10.092144978046417
start training epoch: 92
epoch: 92 |loss: 0.42378146962437313 |cls: 0.2069018271540699 |mse: 0.008435015926806955 |bi: 0.015428004353452707
training time(min): 10.00978090763092
start training epoch: 93
epoch: 93 |loss: 0.4882693891777308 |cls: 0.2391512368558324 |mse: 0.008423519368079724 |bi: 0.01543395623593824
training time(min): 9.42547694047292
start training epoch: 94
epoch: 94 |loss: 0.4701290754164802 |cls: 0.2300936126302986 |mse: 0.008400917578910594 |bi: 0.015409291976538952
training time(min): 10.134405624866485
start training epoch: 95
epoch: 95 |loss: 0.446544805636222 |cls: 0.21829383061776753 |mse: 0.008416144461079966 |bi: 0.015409997155074961
training time(min): 9.832574446996054
start training epoch: 96
epoch: 96 |loss: 0.40282693147310056 |cls: 0.19641894533197046 |mse: 0.008445441771982587 |bi: 0.01543598820353509
training time(min): 9.087192356586456
start training epoch: 97
epoch: 97 |loss: 0.44485958306177054 |cls: 0.2174464346462628 |mse: 0.008424196768828551 |bi: 0.01542519145004917
training time(min): 9.259872917334238
start training epoch: 98
epoch: 98 |loss: 0.43370427109039156 |cls: 0.2118831542757107 |mse: 0.008396987410378642 |bi: 0.015409762021590723
training time(min): 8.795755851268769
start training epoch: 99
epoch: 99 |loss: 0.4515981593285687 |cls: 0.22080962003747118 |mse: 0.00843704775252263 |bi: 0.015418693641549908
training time(min): 8.563793806234996
start training epoch: 100
epoch: 100 |loss: 0.4955255335007678 |cls: 0.2427771327238588 |mse: 0.008429485760643729 |bi: 0.015417821778100915
training time(min): 8.234546446800232
sample: 0
sample: 1
sample: 2
sample: 3
sample: 4
sample: 5
sample: 6
sample: 7
sample: 8
sample: 9
sample: 10
sample: 11
sample: 12
sample: 13
sample: 14
sample: 15
sample: 16
sample: 17
sample: 18
sample: 19
sample: 20
sample: 21
sample: 22
sample: 23
sample: 24
sample: 25
sample: 26
sample: 27
sample: 28
sample: 29
sample: 30
sample: 31
sample: 32
sample: 33
sample: 34
sample: 35
sample: 36
sample: 37
sample: 38
sample: 39
sample: 40
sample: 41
sample: 42
sample: 43
sample: 44
sample: 45
sample: 46
sample: 47
sample: 48
sample: 49
sample: 50
sample: 51
sample: 52
sample: 53
sample: 54
sample: 55
sample: 56
sample: 57
testing epoch: 100 Acc:0.4461
done
