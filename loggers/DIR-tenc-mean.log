gumbel thresh: 0.505
mode: dy+bi+cl model path: ./ModelFile/crossView_NUCLA/Multi/dy+bi+cl/DIR-tenc-mean/ gpu: 3
is_clstoken  True
mean   True
seq_len  5
input projection present encoder:  4025
output projection present encoder:  4025
embed_dim:  8050
embed_proj_dim:  4025
ff_dim:  2048
num_heads:  7
num_layers:  2
dropout:  0.1
seq_len:  5
keys  odict_keys(['backbone.sparseCoding.rr', 'backbone.sparseCoding.theta', 'backbone.transformer_encoder.cls_token', 'backbone.transformer_encoder.input_layer.weight', 'backbone.transformer_encoder.input_layer.bias', 'backbone.transformer_encoder.output_layer.weight', 'backbone.transformer_encoder.output_layer.bias', 'backbone.transformer_encoder.pos_encoder.pe', 'backbone.transformer_encoder.encoder_layer.self_attn.in_proj_weight', 'backbone.transformer_encoder.encoder_layer.self_attn.in_proj_bias', 'backbone.transformer_encoder.encoder_layer.self_attn.out_proj.weight', 'backbone.transformer_encoder.encoder_layer.self_attn.out_proj.bias', 'backbone.transformer_encoder.encoder_layer.linear1.weight', 'backbone.transformer_encoder.encoder_layer.linear1.bias', 'backbone.transformer_encoder.encoder_layer.linear2.weight', 'backbone.transformer_encoder.encoder_layer.linear2.bias', 'backbone.transformer_encoder.encoder_layer.norm1.weight', 'backbone.transformer_encoder.encoder_layer.norm1.bias', 'backbone.transformer_encoder.encoder_layer.norm2.weight', 'backbone.transformer_encoder.encoder_layer.norm2.bias', 'backbone.transformer_encoder.transformer_encoder.layers.0.self_attn.in_proj_weight', 'backbone.transformer_encoder.transformer_encoder.layers.0.self_attn.in_proj_bias', 'backbone.transformer_encoder.transformer_encoder.layers.0.self_attn.out_proj.weight', 'backbone.transformer_encoder.transformer_encoder.layers.0.self_attn.out_proj.bias', 'backbone.transformer_encoder.transformer_encoder.layers.0.linear1.weight', 'backbone.transformer_encoder.transformer_encoder.layers.0.linear1.bias', 'backbone.transformer_encoder.transformer_encoder.layers.0.linear2.weight', 'backbone.transformer_encoder.transformer_encoder.layers.0.linear2.bias', 'backbone.transformer_encoder.transformer_encoder.layers.0.norm1.weight', 'backbone.transformer_encoder.transformer_encoder.layers.0.norm1.bias', 'backbone.transformer_encoder.transformer_encoder.layers.0.norm2.weight', 'backbone.transformer_encoder.transformer_encoder.layers.0.norm2.bias', 'backbone.transformer_encoder.transformer_encoder.layers.1.self_attn.in_proj_weight', 'backbone.transformer_encoder.transformer_encoder.layers.1.self_attn.in_proj_bias', 'backbone.transformer_encoder.transformer_encoder.layers.1.self_attn.out_proj.weight', 'backbone.transformer_encoder.transformer_encoder.layers.1.self_attn.out_proj.bias', 'backbone.transformer_encoder.transformer_encoder.layers.1.linear1.weight', 'backbone.transformer_encoder.transformer_encoder.layers.1.linear1.bias', 'backbone.transformer_encoder.transformer_encoder.layers.1.linear2.weight', 'backbone.transformer_encoder.transformer_encoder.layers.1.linear2.bias', 'backbone.transformer_encoder.transformer_encoder.layers.1.norm1.weight', 'backbone.transformer_encoder.transformer_encoder.layers.1.norm1.bias', 'backbone.transformer_encoder.transformer_encoder.layers.1.norm2.weight', 'backbone.transformer_encoder.transformer_encoder.layers.1.norm2.bias', 'backbone.Classifier.conv1.weight', 'backbone.Classifier.conv1.bias', 'backbone.Classifier.bn1.weight', 'backbone.Classifier.bn1.bias', 'backbone.Classifier.bn1.running_mean', 'backbone.Classifier.bn1.running_var', 'backbone.Classifier.bn1.num_batches_tracked', 'backbone.Classifier.conv2.weight', 'backbone.Classifier.conv2.bias', 'backbone.Classifier.bn2.weight', 'backbone.Classifier.bn2.bias', 'backbone.Classifier.bn2.running_mean', 'backbone.Classifier.bn2.running_var', 'backbone.Classifier.bn2.num_batches_tracked', 'backbone.Classifier.conv3.weight', 'backbone.Classifier.conv3.bias', 'backbone.Classifier.bn3.weight', 'backbone.Classifier.bn3.bias', 'backbone.Classifier.bn3.running_mean', 'backbone.Classifier.bn3.running_var', 'backbone.Classifier.bn3.num_batches_tracked', 'backbone.Classifier.conv4.weight', 'backbone.Classifier.conv4.bias', 'backbone.Classifier.bn4.weight', 'backbone.Classifier.bn4.bias', 'backbone.Classifier.bn4.running_mean', 'backbone.Classifier.bn4.running_var', 'backbone.Classifier.bn4.num_batches_tracked', 'backbone.Classifier.conv5.weight', 'backbone.Classifier.conv5.bias', 'backbone.Classifier.bn5.weight', 'backbone.Classifier.bn5.bias', 'backbone.Classifier.bn5.running_mean', 'backbone.Classifier.bn5.running_var', 'backbone.Classifier.bn5.num_batches_tracked', 'backbone.Classifier.conv6.weight', 'backbone.Classifier.conv6.bias', 'backbone.Classifier.bn6.weight', 'backbone.Classifier.bn6.bias', 'backbone.Classifier.bn6.running_mean', 'backbone.Classifier.bn6.running_var', 'backbone.Classifier.bn6.num_batches_tracked', 'backbone.Classifier.fc.weight', 'backbone.Classifier.fc.bias', 'backbone.Classifier.fc2.weight', 'backbone.Classifier.fc2.bias', 'backbone.Classifier.fc3.weight', 'backbone.Classifier.fc3.bias', 'backbone.Classifier.cls.0.weight', 'backbone.Classifier.cls.0.bias', 'proj.weight', 'proj.bias'])
cls token  tensor([[[ 0.0742, -0.6031, -0.0750,  ..., -1.3075,  0.4966, -0.7540]]],
       device='cuda:3')
rr  tensor([1.0738, 0.9827, 0.9756, 1.1247, 0.9363, 1.0295, 1.0171, 0.8772, 1.1414,
        0.8764, 1.0417, 1.0411, 0.9704, 0.8741, 1.0286, 0.8505, 1.1323, 1.0011,
        0.8609, 0.8905, 0.9876, 1.0116, 0.9802, 0.8808, 1.0316, 1.0559, 1.1463,
        1.0903, 0.9350, 1.0455, 0.9752, 0.8884, 0.8512, 1.0178, 1.0932, 1.1434,
        1.1080, 0.9231, 1.1499, 0.9333, 0.9124, 0.8827, 1.0343, 1.0172, 0.8646,
        1.1115, 0.8968, 1.1214, 1.1036, 1.0951, 0.9496, 1.1026, 1.0418, 0.9571,
        1.0756, 1.0673, 0.8579, 1.1263, 1.0073, 1.1280, 1.0781, 0.8988, 0.9347,
        1.0849, 1.0072, 0.9259, 1.0844, 0.8510, 0.8943, 0.8692, 1.0417, 1.1310,
        0.9874, 0.8866, 0.9528, 0.9757, 0.9415, 1.1430, 0.9416, 1.1242],
       device='cuda:3')
theta  tensor([1.3939, 2.4549, 1.6436, 1.5352, 0.7960, 3.0716, 2.6964, 2.0584, 0.7135,
        2.3078, 1.8680, 1.5814, 2.5930, 2.1385, 0.6050, 1.4292, 1.4744, 0.3818,
        2.0396, 2.8664, 0.4994, 2.8990, 1.4337, 2.9520, 2.1435, 1.2748, 0.3789,
        2.3218, 1.4669, 1.7877, 1.0691, 2.8505, 0.6513, 2.9708, 2.0885, 3.0277,
        1.2882, 1.7110, 2.6468, 2.2400, 1.1219, 0.2007, 0.5942, 0.7402, 2.4891,
        0.8861, 1.3891, 2.8232, 2.3094, 0.7382, 2.3175, 1.3819, 0.8533, 0.4777,
        3.0391, 1.8822, 1.2420, 3.1185, 0.1625, 0.9867, 1.3501, 2.3475, 1.5333,
        1.8721, 1.7133, 1.3431, 0.9326, 3.1381, 1.3014, 2.0869, 1.4987, 1.2876,
        2.5508, 0.4858, 1.6475, 0.5840, 1.7340, 1.2651, 3.0234, 2.8446],
       device='cuda:3')
cls  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:3')
pre_train: /home/balaji/crossView_CL/ModelFile/crossView_NUCLA/Multi/dy+bi+cl/dir-tenc-cl-mean/120.pth
loaded cls token  tensor([[[ 0.0678, -0.5492, -0.0683,  ..., -1.1908,  0.4520, -0.6864]]],
       device='cuda:3')
loaded rr  tensor([1.0599, 0.9743, 0.9663, 1.0703, 0.9268, 1.0206, 1.0072, 0.8694, 1.0412,
        0.8684, 1.0341, 1.0315, 0.9607, 0.8662, 0.9808, 0.8436, 1.0713, 0.9619,
        0.8533, 0.8830, 0.9458, 1.0024, 0.9725, 0.8735, 1.0197, 1.0501, 0.9950,
        1.0803, 0.9276, 1.0258, 0.9668, 0.8809, 0.8451, 1.0097, 1.0486, 1.0795,
        1.0817, 0.9156, 1.0775, 0.9241, 0.9034, 0.9111, 0.9747, 1.0095, 0.8571,
        1.0324, 0.8895, 1.0864, 1.0823, 1.0429, 0.9402, 1.0635, 0.9906, 0.9406,
        1.0659, 1.0572, 0.8507, 1.0796, 0.9868, 1.0320, 1.0559, 0.8908, 0.9269,
        1.0619, 0.9963, 0.9183, 1.0403, 0.8440, 0.8867, 0.8616, 1.0331, 1.0858,
        0.9757, 0.8722, 0.9442, 0.9596, 0.9335, 1.0722, 0.9340, 1.0885],
       device='cuda:3')
loaded theta  tensor([1.3831, 2.4351, 1.6302, 1.5173, 0.7894, 3.0460, 2.6738, 2.0410, 0.7377,
        2.2888, 1.8529, 1.5642, 2.5720, 2.1206, 0.6029, 1.4175, 1.4665, 0.3462,
        2.0224, 2.8426, 0.5185, 2.8750, 1.4217, 2.9278, 2.1216, 1.2670, 0.3556,
        2.2961, 1.4546, 1.7748, 1.0654, 2.8268, 0.6468, 2.9488, 2.0768, 3.0085,
        1.2792, 1.6970, 2.6287, 2.2216, 1.1125, 0.2004, 0.5884, 0.7404, 2.4684,
        0.9092, 1.3778, 2.8066, 2.2928, 0.7396, 2.2984, 1.3781, 0.8437, 0.4658,
        3.0172, 1.8672, 1.2320, 3.0912, 0.1108, 0.9424, 1.3398, 2.3283, 1.5204,
        1.8600, 1.6995, 1.3323, 0.9231, 3.1122, 1.2911, 2.0694, 1.4857, 1.2852,
        2.5297, 0.4884, 1.6341, 0.5822, 1.7197, 1.2677, 2.9984, 2.8182],
       device='cuda:3')
cls  tensor([0.8501, 0.8304, 0.8399, 0.8656, 0.7951, 0.8495, 0.8367, 0.8045, 0.8315,
        0.8346, 0.8355, 0.8365, 0.8201, 0.8282, 0.8473, 0.8448, 0.8442, 0.8319,
        0.8588, 0.8521, 0.8512, 0.8255, 0.8393, 0.8261, 0.8193, 0.8473, 0.8370,
        0.8597, 0.8751, 0.8255, 0.8253, 0.8407, 0.8280, 0.8370, 0.8604, 0.8473,
        0.8651, 0.8447, 0.8318, 0.8487, 0.8350, 0.8500, 0.8274, 0.8022, 0.8475,
        0.8413, 0.8316, 0.8393, 0.8229, 0.8409, 0.8307, 0.8596, 0.8457, 0.8425,
        0.8194, 0.8268, 0.8556, 0.8485, 0.8438, 0.8335, 0.8330, 0.8314, 0.8434,
        0.8416, 0.8375, 0.8239, 0.8493, 0.8421, 0.8607, 0.8365, 0.8267, 0.8485,
        0.8227, 0.8303, 0.8312, 0.8398, 0.8540, 0.8328, 0.8556, 0.8385, 0.8309,
        0.8417, 0.8307, 0.8517, 0.8200, 0.8409, 0.8578, 0.8444, 0.8580, 0.8369,
        0.8484, 0.8407, 0.8439, 0.8353, 0.8539, 0.8189, 0.8311, 0.8423, 0.8446,
        0.8441, 0.8261, 0.8253, 0.8221, 0.8547, 0.8060, 0.8552, 0.8289, 0.8427,
        0.8278, 0.8543, 0.8287, 0.8580, 0.8296, 0.8384, 0.8289, 0.8047, 0.8282,
        0.8393, 0.8169, 0.8399, 0.8317, 0.8332, 0.8359, 0.8187, 0.8432, 0.8413,
        0.8377, 0.8482, 0.8078, 0.8444, 0.8169, 0.8281, 0.8359, 0.8396, 0.8348,
        0.8171, 0.8313, 0.8224, 0.8377, 0.8497, 0.8353, 0.8440, 0.8315, 0.8469,
        0.8102, 0.8078, 0.8342, 0.8510, 0.8388, 0.8352, 0.8547, 0.8424, 0.8494,
        0.8638, 0.8326, 0.8254, 0.8351, 0.8287, 0.8268, 0.8180, 0.8465, 0.8523,
        0.8270, 0.8598, 0.8504, 0.8416, 0.8609, 0.8355, 0.8488, 0.8371, 0.8323,
        0.8245, 0.8379, 0.8567, 0.8400, 0.8372, 0.8174, 0.8401, 0.8387, 0.8265,
        0.8513, 0.8339, 0.8386, 0.8513, 0.8586, 0.8218, 0.8498, 0.8528, 0.8396,
        0.8472, 0.8293, 0.8510, 0.8413, 0.8074, 0.8183, 0.8274, 0.8327, 0.8312,
        0.8321, 0.8269, 0.8460, 0.8453, 0.8475, 0.8408, 0.8407, 0.8244, 0.8354,
        0.8692, 0.8126, 0.8381, 0.8449, 0.8511, 0.8666, 0.8418, 0.8452, 0.8232,
        0.8491, 0.8331, 0.8496, 0.8468, 0.8339, 0.8445, 0.8112, 0.8389, 0.8404,
        0.8571, 0.8222, 0.8481, 0.8239, 0.8462, 0.8429, 0.8447, 0.8126, 0.8151,
        0.8427, 0.8382, 0.8403, 0.8225, 0.8245, 0.8615, 0.8563, 0.8496, 0.8384,
        0.8114, 0.8336, 0.8185, 0.8292, 0.8423, 0.8759, 0.8117, 0.8445, 0.8326,
        0.8141, 0.8503, 0.8149, 0.8300], device='cuda:3')
p  backbone.sparseCoding.rr False
p  backbone.sparseCoding.theta False
p  backbone.transformer_encoder.cls_token False
p  backbone.transformer_encoder.input_layer.weight False
p  backbone.transformer_encoder.input_layer.bias False
p  backbone.transformer_encoder.output_layer.weight False
p  backbone.transformer_encoder.output_layer.bias False
p  backbone.transformer_encoder.encoder_layer.self_attn.in_proj_weight False
p  backbone.transformer_encoder.encoder_layer.self_attn.in_proj_bias False
p  backbone.transformer_encoder.encoder_layer.self_attn.out_proj.weight False
p  backbone.transformer_encoder.encoder_layer.self_attn.out_proj.bias False
p  backbone.transformer_encoder.encoder_layer.linear1.weight False
p  backbone.transformer_encoder.encoder_layer.linear1.bias False
p  backbone.transformer_encoder.encoder_layer.linear2.weight False
p  backbone.transformer_encoder.encoder_layer.linear2.bias False
p  backbone.transformer_encoder.encoder_layer.norm1.weight False
p  backbone.transformer_encoder.encoder_layer.norm1.bias False
p  backbone.transformer_encoder.encoder_layer.norm2.weight False
p  backbone.transformer_encoder.encoder_layer.norm2.bias False
p  backbone.transformer_encoder.transformer_encoder.layers.0.self_attn.in_proj_weight False
p  backbone.transformer_encoder.transformer_encoder.layers.0.self_attn.in_proj_bias False
p  backbone.transformer_encoder.transformer_encoder.layers.0.self_attn.out_proj.weight False
p  backbone.transformer_encoder.transformer_encoder.layers.0.self_attn.out_proj.bias False
p  backbone.transformer_encoder.transformer_encoder.layers.0.linear1.weight False
p  backbone.transformer_encoder.transformer_encoder.layers.0.linear1.bias False
p  backbone.transformer_encoder.transformer_encoder.layers.0.linear2.weight False
p  backbone.transformer_encoder.transformer_encoder.layers.0.linear2.bias False
p  backbone.transformer_encoder.transformer_encoder.layers.0.norm1.weight False
p  backbone.transformer_encoder.transformer_encoder.layers.0.norm1.bias False
p  backbone.transformer_encoder.transformer_encoder.layers.0.norm2.weight False
p  backbone.transformer_encoder.transformer_encoder.layers.0.norm2.bias False
p  backbone.transformer_encoder.transformer_encoder.layers.1.self_attn.in_proj_weight False
p  backbone.transformer_encoder.transformer_encoder.layers.1.self_attn.in_proj_bias False
p  backbone.transformer_encoder.transformer_encoder.layers.1.self_attn.out_proj.weight False
p  backbone.transformer_encoder.transformer_encoder.layers.1.self_attn.out_proj.bias False
p  backbone.transformer_encoder.transformer_encoder.layers.1.linear1.weight False
p  backbone.transformer_encoder.transformer_encoder.layers.1.linear1.bias False
p  backbone.transformer_encoder.transformer_encoder.layers.1.linear2.weight False
p  backbone.transformer_encoder.transformer_encoder.layers.1.linear2.bias False
p  backbone.transformer_encoder.transformer_encoder.layers.1.norm1.weight False
p  backbone.transformer_encoder.transformer_encoder.layers.1.norm1.bias False
p  backbone.transformer_encoder.transformer_encoder.layers.1.norm2.weight False
p  backbone.transformer_encoder.transformer_encoder.layers.1.norm2.bias False
p  backbone.Classifier.conv1.weight False
p  backbone.Classifier.conv1.bias False
p  backbone.Classifier.bn1.weight False
p  backbone.Classifier.bn1.bias False
p  backbone.Classifier.conv2.weight False
p  backbone.Classifier.conv2.bias False
p  backbone.Classifier.bn2.weight False
p  backbone.Classifier.bn2.bias False
p  backbone.Classifier.conv3.weight False
p  backbone.Classifier.conv3.bias False
p  backbone.Classifier.bn3.weight False
p  backbone.Classifier.bn3.bias False
p  backbone.Classifier.conv4.weight False
p  backbone.Classifier.conv4.bias False
p  backbone.Classifier.bn4.weight False
p  backbone.Classifier.bn4.bias False
p  backbone.Classifier.conv5.weight False
p  backbone.Classifier.conv5.bias False
p  backbone.Classifier.bn5.weight False
p  backbone.Classifier.bn5.bias False
p  backbone.Classifier.conv6.weight False
p  backbone.Classifier.conv6.bias False
p  backbone.Classifier.bn6.weight False
p  backbone.Classifier.bn6.bias False
p  backbone.Classifier.fc.weight False
p  backbone.Classifier.fc.bias False
p  backbone.Classifier.fc2.weight False
p  backbone.Classifier.fc2.bias False
p  backbone.Classifier.fc3.weight False
p  backbone.Classifier.fc3.bias False
p  backbone.Classifier.cls.0.weight True
p  backbone.Classifier.cls.0.bias True
p  proj.weight False
p  proj.bias False
cls token  tensor([[[ 0.0678, -0.5492, -0.0683,  ..., -1.1908,  0.4520, -0.6864]]],
       device='cuda:3')
after rr  tensor([1.0599, 0.9743, 0.9663, 1.0703, 0.9268, 1.0206, 1.0072, 0.8694, 1.0412,
        0.8684, 1.0341, 1.0315, 0.9607, 0.8662, 0.9808, 0.8436, 1.0713, 0.9619,
        0.8533, 0.8830, 0.9458, 1.0024, 0.9725, 0.8735, 1.0197, 1.0501, 0.9950,
        1.0803, 0.9276, 1.0258, 0.9668, 0.8809, 0.8451, 1.0097, 1.0486, 1.0795,
        1.0817, 0.9156, 1.0775, 0.9241, 0.9034, 0.9111, 0.9747, 1.0095, 0.8571,
        1.0324, 0.8895, 1.0864, 1.0823, 1.0429, 0.9402, 1.0635, 0.9906, 0.9406,
        1.0659, 1.0572, 0.8507, 1.0796, 0.9868, 1.0320, 1.0559, 0.8908, 0.9269,
        1.0619, 0.9963, 0.9183, 1.0403, 0.8440, 0.8867, 0.8616, 1.0331, 1.0858,
        0.9757, 0.8722, 0.9442, 0.9596, 0.9335, 1.0722, 0.9340, 1.0885],
       device='cuda:3')
after theta  tensor([1.3831, 2.4351, 1.6302, 1.5173, 0.7894, 3.0460, 2.6738, 2.0410, 0.7377,
        2.2888, 1.8529, 1.5642, 2.5720, 2.1206, 0.6029, 1.4175, 1.4665, 0.3462,
        2.0224, 2.8426, 0.5185, 2.8750, 1.4217, 2.9278, 2.1216, 1.2670, 0.3556,
        2.2961, 1.4546, 1.7748, 1.0654, 2.8268, 0.6468, 2.9488, 2.0768, 3.0085,
        1.2792, 1.6970, 2.6287, 2.2216, 1.1125, 0.2004, 0.5884, 0.7404, 2.4684,
        0.9092, 1.3778, 2.8066, 2.2928, 0.7396, 2.2984, 1.3781, 0.8437, 0.4658,
        3.0172, 1.8672, 1.2320, 3.0912, 0.1108, 0.9424, 1.3398, 2.3283, 1.5204,
        1.8600, 1.6995, 1.3323, 0.9231, 3.1122, 1.2911, 2.0694, 1.4857, 1.2852,
        2.5297, 0.4884, 1.6341, 0.5822, 1.7197, 1.2677, 2.9984, 2.8182],
       device='cuda:3')
cls  tensor([0.8501, 0.8304, 0.8399, 0.8656, 0.7951, 0.8495, 0.8367, 0.8045, 0.8315,
        0.8346, 0.8355, 0.8365, 0.8201, 0.8282, 0.8473, 0.8448, 0.8442, 0.8319,
        0.8588, 0.8521, 0.8512, 0.8255, 0.8393, 0.8261, 0.8193, 0.8473, 0.8370,
        0.8597, 0.8751, 0.8255, 0.8253, 0.8407, 0.8280, 0.8370, 0.8604, 0.8473,
        0.8651, 0.8447, 0.8318, 0.8487, 0.8350, 0.8500, 0.8274, 0.8022, 0.8475,
        0.8413, 0.8316, 0.8393, 0.8229, 0.8409, 0.8307, 0.8596, 0.8457, 0.8425,
        0.8194, 0.8268, 0.8556, 0.8485, 0.8438, 0.8335, 0.8330, 0.8314, 0.8434,
        0.8416, 0.8375, 0.8239, 0.8493, 0.8421, 0.8607, 0.8365, 0.8267, 0.8485,
        0.8227, 0.8303, 0.8312, 0.8398, 0.8540, 0.8328, 0.8556, 0.8385, 0.8309,
        0.8417, 0.8307, 0.8517, 0.8200, 0.8409, 0.8578, 0.8444, 0.8580, 0.8369,
        0.8484, 0.8407, 0.8439, 0.8353, 0.8539, 0.8189, 0.8311, 0.8423, 0.8446,
        0.8441, 0.8261, 0.8253, 0.8221, 0.8547, 0.8060, 0.8552, 0.8289, 0.8427,
        0.8278, 0.8543, 0.8287, 0.8580, 0.8296, 0.8384, 0.8289, 0.8047, 0.8282,
        0.8393, 0.8169, 0.8399, 0.8317, 0.8332, 0.8359, 0.8187, 0.8432, 0.8413,
        0.8377, 0.8482, 0.8078, 0.8444, 0.8169, 0.8281, 0.8359, 0.8396, 0.8348,
        0.8171, 0.8313, 0.8224, 0.8377, 0.8497, 0.8353, 0.8440, 0.8315, 0.8469,
        0.8102, 0.8078, 0.8342, 0.8510, 0.8388, 0.8352, 0.8547, 0.8424, 0.8494,
        0.8638, 0.8326, 0.8254, 0.8351, 0.8287, 0.8268, 0.8180, 0.8465, 0.8523,
        0.8270, 0.8598, 0.8504, 0.8416, 0.8609, 0.8355, 0.8488, 0.8371, 0.8323,
        0.8245, 0.8379, 0.8567, 0.8400, 0.8372, 0.8174, 0.8401, 0.8387, 0.8265,
        0.8513, 0.8339, 0.8386, 0.8513, 0.8586, 0.8218, 0.8498, 0.8528, 0.8396,
        0.8472, 0.8293, 0.8510, 0.8413, 0.8074, 0.8183, 0.8274, 0.8327, 0.8312,
        0.8321, 0.8269, 0.8460, 0.8453, 0.8475, 0.8408, 0.8407, 0.8244, 0.8354,
        0.8692, 0.8126, 0.8381, 0.8449, 0.8511, 0.8666, 0.8418, 0.8452, 0.8232,
        0.8491, 0.8331, 0.8496, 0.8468, 0.8339, 0.8445, 0.8112, 0.8389, 0.8404,
        0.8571, 0.8222, 0.8481, 0.8239, 0.8462, 0.8429, 0.8447, 0.8126, 0.8151,
        0.8427, 0.8382, 0.8403, 0.8225, 0.8245, 0.8615, 0.8563, 0.8496, 0.8384,
        0.8114, 0.8336, 0.8185, 0.8292, 0.8423, 0.8759, 0.8117, 0.8445, 0.8326,
        0.8141, 0.8503, 0.8149, 0.8300], device='cuda:3')
optimizer  SGD (
Parameter Group 0
    dampening: 0
    lr: 0.001
    momentum: 0.9
    nesterov: False
    weight_decay: 0.001
)
start training epoch: 0
epoch: 0 |loss: 4.104312779381871 |cls: 2.0471800421364605 |mse: 0.00841281969769625 |bi: 0.015398775747598847
training time(min): 8.247244457403818
sample: 0
sample: 1
sample: 2
sample: 3
sample: 4
sample: 5
sample: 6
sample: 7
sample: 8
sample: 9
sample: 10
sample: 11
sample: 12
sample: 13
sample: 14
sample: 15
sample: 16
sample: 17
sample: 18
sample: 19
sample: 20
sample: 21
sample: 22
sample: 23
sample: 24
sample: 25
sample: 26
sample: 27
sample: 28
sample: 29
sample: 30
sample: 31
sample: 32
sample: 33
sample: 34
sample: 35
sample: 36
sample: 37
sample: 38
sample: 39
sample: 40
sample: 41
sample: 42
sample: 43
sample: 44
sample: 45
sample: 46
sample: 47
sample: 48
sample: 49
sample: 50
sample: 51
sample: 52
sample: 53
sample: 54
sample: 55
sample: 56
sample: 57
testing epoch: 0 Acc:0.2004
start training epoch: 1
epoch: 1 |loss: 3.700814610812813 |cls: 1.8454340007156134 |mse: 0.008405254935496487 |bi: 0.01541352273125085
training time(min): 8.55841345389684
start training epoch: 2
epoch: 2 |loss: 3.5959294699132442 |cls: 1.7929724315181375 |mse: 0.008442441730949213 |bi: 0.015421658223203849
training time(min): 8.791759586334228
start training epoch: 3
epoch: 3 |loss: 3.5194176714867353 |cls: 1.7547280648723245 |mse: 0.008419482168392278 |bi: 0.015420543721120339
training time(min): 8.695653601487477
start training epoch: 4
epoch: 4 |loss: 3.512061723973602 |cls: 1.7510442940983921 |mse: 0.008430798105109716 |bi: 0.015423341443238314
training time(min): 7.046236121654511
start training epoch: 5
epoch: 5 |loss: 3.4974223477765918 |cls: 1.7437348854728043 |mse: 0.00841193831183773 |bi: 0.0154064487433061
training time(min): 6.622072593371073
start training epoch: 6
epoch: 6 |loss: 3.4563968973234296 |cls: 1.7232222990132868 |mse: 0.008410673684920766 |bi: 0.015416214318975108
training time(min): 8.73289628426234
start training epoch: 7
epoch: 7 |loss: 3.4313149000518024 |cls: 1.7106690895743668 |mse: 0.008434230594502878 |bi: 0.015424979133968009
training time(min): 7.174122186501821
start training epoch: 8
epoch: 8 |loss: 3.426809531636536 |cls: 1.7084201122634113 |mse: 0.00842675822059391 |bi: 0.015425517445692094
training time(min): 7.3738047281901045
start training epoch: 9
epoch: 9 |loss: 3.4723956319503486 |cls: 1.7312132671941072 |mse: 0.008428035258475575 |bi: 0.015410543026519008
training time(min): 7.239197214444478
start training epoch: 10
epoch: 10 |loss: 3.400329270865768 |cls: 1.6951705324463546 |mse: 0.008443757333225221 |bi: 0.015444442131411051
training time(min): 7.342663975556691
start training epoch: 11
epoch: 11 |loss: 3.4505673237144947 |cls: 1.7203147285617888 |mse: 0.008398345123168838 |bi: 0.015395174297736958
training time(min): 6.815088888009389
start training epoch: 12
epoch: 12 |loss: 3.455275692977011 |cls: 1.7226575950626284 |mse: 0.00842047483092756 |bi: 0.01540045891306363
training time(min): 6.506871930758158
start training epoch: 13
epoch: 13 |loss: 3.4293916965834796 |cls: 1.7097164965234697 |mse: 0.008416247328568716 |bi: 0.015424607641762123
training time(min): 6.659867084026336
start training epoch: 14
epoch: 14 |loss: 3.3988614408299327 |cls: 1.6944566254969686 |mse: 0.008407577812249656 |bi: 0.015406130263727391
training time(min): 7.221108464399974
start training epoch: 15
epoch: 15 |loss: 3.3515679566189647 |cls: 1.6708075273782015 |mse: 0.008410559734329581 |bi: 0.015423500659380807
training time(min): 7.423858118057251
start training epoch: 16
epoch: 16 |loss: 3.3799024331383407 |cls: 1.6849509635940194 |mse: 0.008458097247057594 |bi: 0.015424076893395977
training time(min): 7.2155962983767195
start training epoch: 17
epoch: 17 |loss: 3.4253715313971043 |cls: 1.7076951644849032 |mse: 0.008438759005002794 |bi: 0.015424418059410527
training time(min): 7.391358053684234
start training epoch: 18
epoch: 18 |loss: 3.3787091514095664 |cls: 1.684387290617451 |mse: 0.008394893059630704 |bi: 0.01539681952635874
training time(min): 7.540413117408752
start training epoch: 19
epoch: 19 |loss: 3.371647084597498 |cls: 1.6808432650286704 |mse: 0.008419934869380086 |bi: 0.01540612270400743
training time(min): 7.447522826989492
start training epoch: 20
epoch: 20 |loss: 3.3640614710748196 |cls: 1.677046621683985 |mse: 0.008425048838034854 |bi: 0.015431954634550493
training time(min): 7.647000094254811
sample: 0
sample: 1
sample: 2
sample: 3
sample: 4
sample: 5
sample: 6
sample: 7
sample: 8
sample: 9
sample: 10
sample: 11
sample: 12
sample: 13
sample: 14
sample: 15
sample: 16
sample: 17
sample: 18
sample: 19
sample: 20
sample: 21
sample: 22
sample: 23
sample: 24
sample: 25
sample: 26
sample: 27
sample: 28
sample: 29
sample: 30
sample: 31
sample: 32
sample: 33
sample: 34
sample: 35
sample: 36
sample: 37
sample: 38
sample: 39
sample: 40
sample: 41
sample: 42
sample: 43
sample: 44
sample: 45
sample: 46
sample: 47
sample: 48
sample: 49
sample: 50
sample: 51
sample: 52
sample: 53
sample: 54
sample: 55
sample: 56
sample: 57
testing epoch: 20 Acc:0.2371
start training epoch: 21
epoch: 21 |loss: 3.347312804311514 |cls: 1.6686632388737053 |mse: 0.008442982913038577 |bi: 0.015433311753440648
training time(min): 7.506424224376678
start training epoch: 22
epoch: 22 |loss: 3.3802812774665654 |cls: 1.6851413897238672 |mse: 0.008454192669887561 |bi: 0.015442994015756994
training time(min): 7.361841281255086
start training epoch: 23
epoch: 23 |loss: 3.3607077817432582 |cls: 1.67538246861659 |mse: 0.008402093128097476 |bi: 0.015407434333610581
training time(min): 7.403878390789032
start training epoch: 24
epoch: 24 |loss: 3.3278839397244155 |cls: 1.6589689021930099 |mse: 0.008404247246289742 |bi: 0.015419042440043995
training time(min): 7.464245895544688
start training epoch: 25
epoch: 25 |loss: 3.4004351440817118 |cls: 1.6952347622718662 |mse: 0.008423917724940111 |bi: 0.015416957401612308
training time(min): 7.593283069133759
start training epoch: 26
epoch: 26 |loss: 3.339640091173351 |cls: 1.6648284492548555 |mse: 0.008438906068477081 |bi: 0.01544278168148594
training time(min): 7.514370425542196
start training epoch: 27
epoch: 27 |loss: 3.4173983773216605 |cls: 1.7037178333848715 |mse: 0.008420239097176818 |bi: 0.015424691016960423
training time(min): 7.294543528556824
start training epoch: 28
epoch: 28 |loss: 3.437483703251928 |cls: 1.7137630223296583 |mse: 0.00841638876045181 |bi: 0.015412673576065572
training time(min): 7.277466062704722
start training epoch: 29
epoch: 29 |loss: 3.3670864263549447 |cls: 1.6785697506275028 |mse: 0.00840784048432397 |bi: 0.015390852513519349
training time(min): 7.399659387270609
start training epoch: 30
epoch: 30 |loss: 3.3600746151059866 |cls: 1.6750554877799004 |mse: 0.008420656087764655 |bi: 0.015429907449288294
training time(min): 7.373323241869609
start training epoch: 31
epoch: 31 |loss: 3.3525244630873203 |cls: 1.6712643820792437 |mse: 0.008451803138086689 |bi: 0.015438846665347228
training time(min): 7.314153623580933
start training epoch: 32
epoch: 32 |loss: 3.3636991190724075 |cls: 1.6768713125493377 |mse: 0.00841552798738121 |bi: 0.015409716546855634
training time(min): 7.581376294294993
start training epoch: 33
epoch: 33 |loss: 3.279868718702346 |cls: 1.6349404486827552 |mse: 0.008443570612143958 |bi: 0.015442645199073013
training time(min): 7.207719182968139
start training epoch: 34
epoch: 34 |loss: 3.2852375712245703 |cls: 1.6376503861974925 |mse: 0.008396582845307421 |bi: 0.015402073884615675
training time(min): 7.54026958545049
start training epoch: 35
epoch: 35 |loss: 3.3538490389473736 |cls: 1.6719364551827312 |mse: 0.008433497092482867 |bi: 0.015426245332491817
training time(min): 7.637536152203878
start training epoch: 36
epoch: 36 |loss: 3.286604627966881 |cls: 1.6383147810120136 |mse: 0.008432555900071748 |bi: 0.01542526729463134
training time(min): 8.2587508837382
start training epoch: 37
epoch: 37 |loss: 3.329075390007347 |cls: 1.6595502365380526 |mse: 0.008432823153270874 |bi: 0.015420922754856292
training time(min): 8.87501015663147
start training epoch: 38
epoch: 38 |loss: 3.3543495452031493 |cls: 1.6721794188488275 |mse: 0.008446412317425711 |bi: 0.015442857478774386
training time(min): 9.742022482554118
start training epoch: 39
epoch: 39 |loss: 3.3305320227518678 |cls: 1.6602772411424667 |mse: 0.008433793134827283 |bi: 0.015437398411449976
training time(min): 10.382260346412659
start training epoch: 40
epoch: 40 |loss: 3.313860272988677 |cls: 1.6519553291145712 |mse: 0.00840836339739326 |bi: 0.015412521926918998
training time(min): 9.9481752038002
sample: 0
sample: 1
sample: 2
sample: 3
sample: 4
sample: 5
sample: 6
sample: 7
sample: 8
sample: 9
sample: 10
sample: 11
sample: 12
sample: 13
sample: 14
sample: 15
sample: 16
sample: 17
sample: 18
sample: 19
sample: 20
sample: 21
sample: 22
sample: 23
sample: 24
sample: 25
sample: 26
sample: 27
sample: 28
sample: 29
sample: 30
sample: 31
sample: 32
sample: 33
sample: 34
sample: 35
sample: 36
sample: 37
sample: 38
sample: 39
sample: 40
sample: 41
sample: 42
sample: 43
sample: 44
sample: 45
sample: 46
sample: 47
sample: 48
sample: 49
sample: 50
sample: 51
sample: 52
sample: 53
sample: 54
sample: 55
sample: 56
sample: 57
testing epoch: 40 Acc:0.2457
start training epoch: 41
epoch: 41 |loss: 3.3794620377011597 |cls: 1.684750240528956 |mse: 0.008420000855039689 |bi: 0.015415600155392895
training time(min): 9.852393718560537
start training epoch: 42
epoch: 42 |loss: 3.3348644063808024 |cls: 1.6624574423767626 |mse: 0.008408211719142855 |bi: 0.015412999568070518
training time(min): 10.052422372500102
start training epoch: 43
epoch: 43 |loss: 3.3509741807356477 |cls: 1.670514122582972 |mse: 0.00840578672978154 |bi: 0.015401512806420214
training time(min): 10.076501067479452
start training epoch: 44
epoch: 44 |loss: 3.323747806251049 |cls: 1.6569052934646606 |mse: 0.008397129173317808 |bi: 0.015400959360704292
training time(min): 10.141477799415588
start training epoch: 45
epoch: 45 |loss: 3.3350946153514087 |cls: 1.6625614964868873 |mse: 0.00842903553711949 |bi: 0.015425858662638348
training time(min): 10.388721036911011
start training epoch: 46
epoch: 46 |loss: 3.2540926644578576 |cls: 1.622064758092165 |mse: 0.00842262332480459 |bi: 0.015405326601467095
training time(min): 10.377792024612427
start training epoch: 47
epoch: 47 |loss: 3.3830569623969495 |cls: 1.6865215438883752 |mse: 0.008467324749290128 |bi: 0.01546552015497582
training time(min): 10.23665657043457
start training epoch: 48
epoch: 48 |loss: 3.3711465522646904 |cls: 1.6805880728643388 |mse: 0.008429006460573873 |bi: 0.015414038334711222
training time(min): 10.30769114891688
start training epoch: 49
epoch: 49 |loss: 3.3540897192433476 |cls: 1.67207450279966 |mse: 0.008399417905820883 |bi: 0.015412946548167383
training time(min): 10.424935408433278
start training epoch: 50
epoch: 50 |loss: 3.1305266870185733 |cls: 1.560289076762274 |mse: 0.008406831466345466 |bi: 0.015416927042679163
training time(min): 9.902027134100596
start training epoch: 51
